# 운영체제란

대표적인 시스템 소프트웨어

## 운영체제의 역할

1. 자원 관리로 컴퓨터 시스템을 효율적으로 운영하는 것

- 하드웨어 자원
- 소프트웨어 자원

2. 사용자 지원
   운영체제는 사용자가 내린 명령을 해석하여 실행하며 사용자와 하드웨어 사이의 매개체 역할을 하면서 사용자에게 편의성을 제공

## 모드

1. 커널 모드
   하드웨어를 직접 제어할 수 있는 CPU의 명령어를 사용할 수 있는 모드
1. 일체형 커널
   운영체제의 모든 서비스가 커널 내에 포함된 커널
1. 마이크로커널
   운영체제 요소의 대부분을 커널 외부로 분리하여 커널 내부에는 메모리 관리, 프로세스 간 통신, 멀티태스킹 등 최소한 요소만 남겨 놓은 커널

1. 사용자 모드(보호 모드)
   하드웨어를 직접 제어할 수 있는 CPU의 명령어를 사용할 수 없는 모드

- 커널 모드에서는 운영체제만 동작하므로 응용 프로그램은 사용자 모드에서만 동작한다
- 시스템 호출: 응용 프로그램이 하드웨어에 대한 제어가 필요한 경우 운영체제에 서비스를 요청하는 메커니즘

## 운영체제의 구성

1. 프로세스 관리자

- CPU를 할당하기 위한 스케줄을 결정
- 프로세스의 상태를 관리

2. 메모리 관리자

- 메모리 할당 및 회수
- 운영체제가 직접 사용하는 메모리 공간에 응용 프로그램의 프로세스가 접근하지 못하도록 해야함

3. 장치 관리자

- 컴퓨터 시스템의 모든 장치를 관리

4. 파일 관리자

- 프로그램 파일과 데이터 파일을 관리
- 저장장치의 공간과 파일의 생성, 수정 등의 접근 제한도 관리

## 운영체제의 유형

1. 일괄처리 운영체제
   작업을 모아서 순서대로 처리하는 방식

2. 시분할 운영체제
   사용자의 프로그램을 한번에 조금씩 수행하여 여러 프로그램이 동시에 실행되는 것과 비슷한 효과를 내는 방식
   요청한 시점부터 반응이 시작되는 시점까지의 소요시간을 의미하는 응답시간이 일괄처리 운영체제보다 크게 단축됨

3. 실시간 운영체제
   원하는 시간 내에 프로그램의 결과를 얻을 수 있는 운영체제
   즉 처리기한을 맞추는 것이 중요한 우선순위가 높은 작업을 우선 처리할 수 있는 기법 활용

4. 분산 운영체제
   네트워크를 통해 다른 컴퓨터 시스템의 자원을 이용하는 것이 자신의 컴퓨터 시스템에 있는 자원을 이용하는 것처럼 가능하도록 함

---

# 프로세스

실행 중인 프로그램

- 프로그램은 디스크 내 파일로 존재하는 동작하지 않는 정적이며 수동적인 개체
- 프로세스는 프로그램을 실행시킨 것으로 운영체제로부터 프로그램이 동작을 하는데 필요한 CPU, 메모리, 입출력장치, 파일 등의 자원을 할당받아 동작을 시작한 것, 능동적인 개체
- 하나의 메모리 구조를 갖고 그 안의 코드 영역에 대해 하나의 제어 흐름을 가짐 -> 코드 영역, 정적 데이터 영역, 스택 영역, 힙 영역
- 프로그램 카운터가 가리키는 명령을 처리하는데 하나의 프로세스는 하나의 PC만 유지하므로 제어 흐름을 하나만 갖기 때문에 기본적으로 다중 처리가 불가능하다는 특징이 있다.

## 프로세스의 구성

- 메모리 구조
- 코드 영역: 프로그램 자체
- 데이터 영역
- 정적 데이터: 상수, 전역변수
- 스택: 지역변수, 매개변수
- 힙: 동적
- 프로세스 제어 블록(PCB): 프로세스의 정보를 보관

- PID: 프로세스 식별자
- PC(프로그램 카운터): 다음에 실행할 명령의 주소
- 상태
- 레지스터
- 프로세스 우선순위
- 메모리 관리 정보: 프로세스가 저장된 주소와 가상 메모리의 실주소의 사상 정보 등
  운영체제는 보통 여러 프로세스를 동시에 관리하며 번갈아 실행시키게 된다. 실행 중이던 프로세스의 정보를 PCB에 저장한 후 나중에 이 프로세스를 다시 실행하게 되면 프로세스 제어 블록에 저장된 정보를 이용하여 이어서 실행한다.

## 프로세스 상태 관리

1. 생성: 처음 작업이 주어진 상태로 프로세스 제어 블록을 생성하고 작업 큐에 넣는다.
2. 준비: 프로세스의 메모리 구조가 생성되어 CPU 할당을 기다리는 상태로 준비 큐에 머물다가 CPU를 할당받으면 실행 상태로 전이된다.
3. 실행: 프로세스가 처리되는 상태, CPU를 할당하는 과정을 디스패치라고 한다.

- 스케줄러가 준비 큐에서 다른 프로세스를 선택하게 되면 실행 상태의 프로세스는 CPU를 회수당하고 준비 상태로 전이된다.
- 실행 상태 프로세스가 입출력을 요구하는 작업이나 페이지 교환을 요구하는 작업을 만나면 대기 상태로 전이된다. (이러한 작업은 상대적으로 오랜 시간이 걸리기 때문에 CPU를 다른 프로세스에 할당하여 활용하기 위함)

4. 대기: 프로세스가 I/O 작업이 끝날 때까지 특정 자원을 할당 받을 때까지 보류되는 상태
5. 종료: 프로세스가 더 이상 실행되지 않도록 끝난 상태

## 부모 프로세스/자식 프로세스

한 프로세스가 다른 프로세스를 생성하는 방법 -> 프로세스 생성 시스템 호출

1. 부모 프로세스: 시스템 호출을 하는 프로세스
2. 자식 프로세스: 시스템 호출을 통해 새로 생성된 프로세스

- UNIX, Linux

  - fork() 시스템 호출을 통해 부모 프로세스의 복제본인 자식 프로세스 생성 (부모 프로세스의 메모리 구조와 동일)
  - exec() 을 사용하면 자식 프로세스가 부모 프로세스와 다른 프로그램을 실행함

- Windows
  - CreateProcess() 시스템 호출 사용, 이는 처음부터 새로운 프로그램으로 자식 프로세스를 생성

## 프로세스 종료

- 일반적인 경우: 프로세스의 마지막 명령이 실행을 마쳐 모든 처리를 완료하고 정상적으로 종료
- 부모 프로세스가 자식 프로세스의 번호를 이용하여 프로세스 종료 시스템 호출로 종료
- 부모 프로세스가 종료되는 경우 운영체제에 의해 자식 프로세스들이 모두 종료

다만 자식 프로세스가 종료되어 자원이 회수되더라도 자식 프로세스의 프로세스 제어 블록(PCB)은 부모 프로세스가 결과를 받을 때까지 사라지지 않고 유지 된다.

---

# 쓰레드

프로세스 내에서 다중 처리를 위해 제안된 개념
(자원 소유의 단위는 프로세스, 디스패칭의 단위는 쓰레드)

- 쓰레드마다 프로그램 카운터(PC)가 있어 쓰레드별로 디스패칭이 가능 (+레지스터, 스택)
- 각 쓰레드는 실행에 필요한 최소한의 정보만 가짐 (그 외 정보는 프로세스에 두고 다른 쓰레드와 공유)
- 쓰레드 또한 프로세스처럼 생성, 준비, 실행, 대기, 종료상태를 가짐

---

# 프로세스 스케줄링

1. 상위단계 스케줄링(장기 스케줄링)
   시스템에 들어와 작업 큐에 있는 작업을 선택하여 프로세스를 생성한 뒤 프로세스 준비 큐에 전달
   - 입출력 중심 작업/연산 중심 작업을 균형있게 선택하도록 작업순서 결정
2. 중간단계 스케줄링(중기 스케줄링)
   프로세스를 일시적으로 메모리에서 제거하여 중지시키거나 중지된 프로세스에 다시 메모리를 할당하여 활성화시켜 시스템에 대한 단기적인 부하를 조절하는 역할
   - 시스템이 과부하되는 경우 메모리에서 어떤 프로세스를 제거해야 시스템의 부하가 줄어들지를 결정하여 실제로 중지시켜준다
3. 하위단계 스케줄링(단기 스케줄링)
   준비큐에 있는 프로세스를 선택하여 사용 가능한 CPU를 할당하는 역할

## 스케줄링의 목표

1. 공정성: 모든 프로세스가 적정 수준에서 CPU 작업을 할 수 있게 하는 것
2. 균형성: 시스템의 자원들이 충분히 활용될 수 있게 하는 것

### 목표 기준

1. 처리량(throughput): 주어진 시간에 처리한 프로세스 수
2. 반환시간(turnaround time): 프로세스 생성 시점부터 종료 시점까지의 소요시간
3. 응답시간(response time): 요청한 시점부터 반응이 시작되는 시점까지의 소요시간
4. 대기시간(waiting time): 프로세스가 종료될 때까지 준비큐에 기다린 시간의 합

### 일괄처리 운영체제 목표

처리량의 극대화, 반환시간의 최소화, CPU 활용의 극대화

### 시분할 운영체제 목표

빠른 응답시간, 과다한 대기 시간 방지

### 실시간 운영체제 목표

처리기한 맞추기

## 스케줄링 정책(하위단계 스케줄링)

1. 선점 스케줄링 정책

- 실행 중인 프로세스에 인터럽트를 걸고 다른 프로세스에 CPU를 할당할 수 있는 스케줄링 방식
- 높은 우선순위의 프로세스를 우선 처리해야 하는 경우 유용
- 컨텍스트 스위칭이 일어나며 오버헤드 발생
  - 컨텍스트란 CPU의 모든 레지스터와 운영체제에 따라 요구되는 프로세스의 상태
  - 컨텍스트 스위칭은 CPU가 현재 실행하고 있는 프로세스의 문맥을 프로세스 제어 블록에 저장하고 다른 프로세스의 프로세스 제어 블록으로부터 문맥을 복원하는 작업

2. 비선점 스케줄링 정책

- 실행 중인 프로세스를 바로 준비상태로 전이시킬 수 없는 스케줄링 방식
- CPU를 할당받아 실행이 시작된 프로세스는 대기/종료상태로 전이될 때까지 계속 실행상태에 있게 된다

## 스케줄링 평가 기준

1. 평균대기시간: 각 프로세스가 수행이 완료될 때까지 준비큐에서 기다리는 시간의 합의 평균값
2. 평균반환시간: 각 프로세스가 생성된 시점부터 수행이 완료된 시점까지의 소요시간의 평균값
   - 프로세스 생성 시간과 대기상태에서의 시간도 모두 포함

## 스케줄링 알고리즘

1. 비선점 방식

   1. FCFS 스케줄링
      프로세스는 준비 큐에 도착한 순서에 따라 디스패치되며 한 프로세스가 CPU를 차지하면 그 프로세스의 수행이 완료된 후 다음 프로세스가 CPU를 차지하고 수행된다

      - 프로세스들의 도착순서에 따라 평균반환시간이 크게 변함
      - 우선순위에 따른 프로세스를 처리하는 방법이 최근 사용되는데, 그 중에서도 우선순위가 같은 경우 FCFS를 적용

   2. SJF 스케줄링 (Shortest Job First)
      준비 큐에서 기다리는 프로세스 중 실행시간이 가장 짧다고 예상되는 것을 먼저 디스패치하여 실행

      - CPU 사이클이 미리 주어져야만 적용 가능 (미리 예상 불가)
      - 실행예정시간의 길이를 사용자 추정에 의존
      - 비선점이므로 새로 들어온 짧은 작업이 실행 중인 긴 작업을 기다리게 되기도 하므로 시분할 운영체제나 실시간 운영체제는 적합하지 않음

   3. HRN 스케줄링 (Highest Response Ratio Next)
      준비 큐에서 기다리는 프로세스 중 응답비율이 가장 큰 것을 먼저 디스패치하여 실행
      - 응답비율 = (대기시간+예상실행시간) / 예상실행시간
      - 응답비율은 예상실행시간이 짧고 대기시간이 길수록 커짐, 즉 모든 프로세스가 동시에 준비 큐에 들어온다면 예상실행시간이 가장 짧은 프로세스가 선택되고 예상실행시간이 모두 동일한 프로세스지만 준비큐에 들어온 시각이 모두 다르다면 대기시간이 가장 긴 프로세스가 선택됨

2. 선점 방식

   1. SRT 스케줄링 (Shortest Remaining Time)
      준비 큐에서 기다리는 프로세스 중 남은 실행시간이 가장 짧다고 예상되는 것을 먼저 디스패치하여 실행

      - 실행예정시간의 길이를 사용자 추정에 의존
      - 실행되는 각 프로세스의 실행시간을 추적하여 각 프로세스가 서비스를 받은 시간을 기록해야 하며, 선점을 위한 컨텍스트 스위칭도 해야 하므로 오버헤드가 SJF보다 크다

   2. RR 스케줄링 (Round Robin)
      프로세스가 도착한 순서대로 프로세스를 디스패치하지만 정해진 시간 할당량(시간각격)에 의해 실행을 제한

      - 시분할 운영체제에 적합
      - 시간 할당량을 어떻게 정하느냐에 따라 성능이 크게 달라진다
      - 프로세스가 한 번에 처리할 양을 처리할 수 있는 정도가 적당

   3. 다단계 피드백 큐 스케줄링
      입출력 중심인 프로세스와 연산 중심인 프로세스의 특성에 따라 서로 다른 시간 할당량을 부여
      - n 개의 단계가 있는 경우, 각 단계마다 하나씩의 준비큐가 존재하고 단계가 커질수록 시간 할당량은 커지는 형태
      - 하나의 단계에서 디스패치가 일어나면 다른 단계에선 디스패치 불가
      - 연산 위주의 프로세스는 시간 할당량 안에 종료되지 못하고 점점 단계가 커지고, 입출력 위주의 프로세스는 시간 할당량보다 짧은 실행이 유지되어 작은 단계를 유지한다

---

# 병행 프로세스

## 병행성

여러 개의 프로세스나 쓰레드가 동시에 수행되는 시스템의 특성

## CPU 개수

- 인터리빙 방식: CPU 1개에서 병행 프로세스가 실행되는 경우
  - 한순간에 하나의 프로세스가 실행
- 병렬처리 방식: 여러 개의 CPU(멀티프로세서) 시스템
  - 메모리 구조에 따라 실행되는 형태가 차이남
  - 강결합 시스템에서는 여러 CPU가 하나의 기억장치를 공유 (master/slave 환경, SMP-Symmetric MultiProcessing)
  - 약결합 시스템에서는 2개 이상의 독립된 컴퓨터 시스템이 네트워크로 서로 연결된 형태 즉 각 시스템은 자신의 운영체제와 기억장치를 가지고 독자적으로 운영
  - 시스템 간 통신을 위해 메시지 전달이나 원격 프로시저 호출(IPC) 사용

## 독립 프로세스

수행 중인 다른 프로세스에 영향을 주지 않고 받지도 않는 프로세스

- 자신이 사용하는 데이터를 다른 프로세스와 공유 X
- 결정적
- 재생 가능
  => 다른 프로세스의 영향을 받지 않으므로 입력 데이터만 동일하다면 실행결과는 항상 동일

## 협력 프로세스

수행 중인 다른 프로세스와 영향을 주고받으며 동작하는 프로세스

- 다른 프로세스와 데이터와 상태를 공유
- 비결정적
- 재생 불가
  => 다른 프로세스의 영향을 받을 수 있으므로 입력 데이터가 동일하더라도 실행 결과가 달라질 수 있음

---

# 병행성 문제

## 상호 배제

2개 이상의 프로세스가 동시에 임계영역을 수행하지 못하도록 하는 것

### 임계영역

2개의 프로세스가 동시에 사용하면 안되는 공유자원을 액세스하는 프로그램 코드 영역

## 동기화

2개 이상의 프로세스에 대한 처리순서를 결정하는 것

## 프로세스 간 통신 (IPC)

프로레스들이 데이터를 공유하기 위해 반드시 필요한 것

1. 변수 사용
2. 메시지 송수신

---

# 세마포어

상호배제와 동기화 문제를 해결하기 위한 도구

- 정수형 공용변수
- 사용 가능한 자원의 수, 잠김이나 풀림의 상태값 등의 초기화 필요
- P, V연산의 기본연산만 사용, 해당 연산은 인터럽트 되지 않고 하나의 단위로 처리됨

"""
void P (semaphore s) {
if (s > 0) s--;
else 현재 프로세스를 대기시킴;
}

void V (semaphore s) {
if (대기 중인 프로세스 없음) s++;
else 대기 중인 프로세스 1개 진행;
}
"""

## 상호배제 해결

한 프로세스가 임계영역을 수행 중이라면 다른 프로세스는 임계영역에 진입해서 안되며, 임계영역을 수행 중이던 프로세스가 임계영역에서 벗어나면 대기 중인 프로세스 중 하나는 새로이 임계영역을 수행해야 한다.

- 진입영역 -> P 연산
- 해제영역 -> V 연산
- 세마포어 초기값 1: 수행 시작 가능 여부

## 동기화 해결

A 프로세스가 S1를 수행한 뒤 B 프로세스 S2 를 수행하도록 동기화 하려면 S2 앞에 P 연산을 두고 S1 뒤에 V 연산을 두어 동기화할 수 있다.

- 세마포어 초기값 0: S1이 아직 수행되지 않음을 의미

---

# 병행 프로세스

## 생산자-소비자 문제 (유한 버퍼 문제)

두 협력 프로세스 사이 버퍼를 두고 한쪽 프로세스는 데이터를 넣고, 다른 프로세스는 데이터를 꺼내는 상황을 다루는 문제

## 생산자-소비자 문제 조건

1. 버퍼에 여러 프로세스가 동시에 접근 불가
2. 버퍼의 크기가 유한함
   => 상호배제와 동기화가 필요

## 세마포어를 이용한 해결

- mutex = 1 => 상호배제
  - 생산자가 버퍼에 데이터를 넣는 부분과 소비자가 버퍼에서 데이터를 꺼내는 부분은 임계영역이 된다
- empty = n (버퍼 수) => 동기화
  - 버퍼가 가득 찼을 때, 버퍼에 존재하는 빈 공간의 개수를 의미
  - 생산자가 데이터를 생산하더라도 소비자가 버퍼에서 데이터를 꺼낸 후에야 버퍼에 데이터를 넣을 수 있다
- full = 0 => 동기화
  - 버퍼가 빈 경우, 데이터의 개수를 의미
  - 소비자가 사용할 데이터가 없다면 생산자가 버퍼에 데이터를 넣은 후에야 소비자가 버퍼에서 데이터를 꺼낼 수 있다

---

# 판독기-기록기 문제

여러 협력 프로세스가 파일 같은 공유자원을 사이에 두고 데이터를 쓰거나 데이터를 읽는 상황을 다루는 문제

## 판독기-기록기 문제의 구체적인 조건

1. 기록기가 공유자원에 데이터를 쓰는 중에 다른 기록기나 판독기는 공유자원에 접근할 수 없다 => 상호배제 필요
2. 여러 판독기는 동시에 공유자원에서 데이터를 읽을 수 있다

## 제1판독기-기록기 문제

판독기가 공유자원에 접근 중이라면 기록기보다 판독기에 우선순위를 주는 것

- 대기 중인 기록기가 있든 없든 새로운 판독기는 즉시 공유자원에 접근할 수 있다
- 기록기가 기아상태에 빠질 수 있다
  - 기아상태: 프로세스가 필요한 자원을 할당받지 못하고 계속적으로 대기하게 되는 상황

## 제2판독기-기록기 문제

판독기가 공유자원에 접근 중이라면 판독기보다 기록기 우선순위를 주는 것

- 대기 중인 기록기가 있으면 새로운 판독기는 두번째 조건에도 불구하고 공유자원에 접근할 수 없다
- 기록기의 기아상태를 방지하지만 판독기의 병행성이 떨어지거나 판독기가 기아상태에 빠질 수 있다

## 세마포어를 이용한 해결

1. 제1판독기-기록기 문제

   - wrt = 1 (세마포어)

     - 기록기에 대한 상호배제
     - 기록기가 공유자원에 데이터를 쓰는 부분은 다른 기록기가 쓰거나 판독기가 읽는 부분과 동시에 수행될 수 없으므로 임계영역이다
     - 판독기가 공유자원에서 데이터를 읽는 부분은 기록기가 쓰는 부분과 동시에 수행될 수 없으므로 임계영역이다

   - rcount = 0 (일반 변수)
     - 하나의 판독기가 임계영역을 수행 중일 때 다른 판독기도 임계영역을 수행할 수 있어야 하므로 일반 변수 rcount 를 두어 동시에 공유자원의 데이터를 읽는 판독기의 개수를 유지
     - rcount 가 1이상이 되면 공유자원을 읽는 판독기가 이미 있다는 것이므로 상호배제가 되지 않도록 P 연산을 생략한다
     - 임계영역 수행이 끝나고 rcount 를 1 줄였을 때 여전히 0보다 크다면 다른 판독기가 있다는 의미이므로 V 연산을 수행하지 않도록 한다
     - rcount 를 변화하고 확인하는 작업은 다른 판독기에 방해를 받으면 안되므로 임계영역으로 보고 mutex 를 사용하여 상호배제 처리 해준다
   - mutex = 1 (세마포어)
     - rcount 의 상호배제

   """ 기록기의 코드
   P(wrt)
   공유자원에 쓰기
   V(wrt)
   """

   """ 판독기의 코드
   P(mutex)
   rcount = rcount + 1
   if (rcount == 1) then P(wrt)
   V(mutex)
   공유자원 읽기
   P(mutex)
   rcount = rcount - 1
   if (rcount == 0) then V(wrt)
   V(mutex)
   """

2. 제2판독기-기록기 문제

   - rd = 1
   - wrt = 1
   - mutex1 = 1
   - mutex2 = 1
   - mutex3 = 1
   - rcount = 0
   - wcount = 0

   """ 기록기 코드
   P(mutex2)
   wcount = wcount + 1
   if (wcount == 1) then P(rd)
   V(mutex2)
   P(wrt)
   공유자원에 쓰기
   V(wrt)
   P(mutex2)
   wcount = wcount - 1
   if (wcount == 0) then V(rd)
   V(mutex2)
   """

   """ 판독기 코드
   P(mutex3)
   P(rd)
   P(mutex1)
   rcount = rcount + 1
   if (rcount == 1) then P(wrt)
   V(mutex1)
   V(rd)
   V(mutex3)
   공유자원 읽기
   P(mutex1)
   rcount = rcount - 1
   if (rcount == 0) then V(wrt)
   V(mutex1)
   """

# 프로세스 간 통신 (InterProcess Communication IPC)

병행 프로세스가 데이터를 서로 공유하는 방법

1. 공유 메모리 방법
   협력 프로세스가 동일한 변수(공유 자원)를 사용하여 데이터를 서로 공유하는 방법

   - 메모리에 직접 접근하여 대량의 데이터를 쓰거나 읽기에 적합
   - 빠른 속도
   - 상호배제나 동기화 등 문제를 응용 프로그래머가 책임

2. 메시지 전달 방법
   협력 프로세스가 메시지를 주고 받으면서 데이터를 서로 공유하는 방법

   - 커널모드에서 작동하는 send, receive 연산 사용
   - 시스템 호출을 사용하므로 소량의 데이터를 주고 받는데 적절
   - 운영체제가 상호배제나 동기화 문제에 책임

   * 통신 링크
     두 프로세스가 서로 메시지를 주고 받을 때 두 프로세스 사이에는 통신 링크가 존재

     - 링크의 방향성은 단방향/양방향 가능
     - 하나의 링크가 두 개의 프로세스만 연결하도록 하거나 여러 프로세스를 연결하도록 할 수 도 있음
     - 링크의 용량은 버퍼(큐)에 보관할 수 있는 메시지 수

   1. 직접통신
      두 프로세스가 직접 서로를 지정하여 메시지를 주고 받는 방법

   - 송신자는 send 연산에 수신자를 명시
   - 수신자는 receive 연산에 송신자를 명시
   - 직접통신은 서로를 지정한 두 프로세스 사이에 오직 하나의 통신 링크가 자동으로 설정됨
   - 양방향성
   - 송수신자가 각각 상대를 직접 명시하는 경우 대칭형 주소 지정, 수신자가 송신자를 미리 지정하지 않고 메시지를 받을 때 송신자 이름도 받는 경우 비대칭형 주소 지정

   2. 간접통신
      통신을 원하는 프로세스들 사이에 우편함을 두고 이를 통해 메시지를 주고 받는 방법

   - 송신자는 send 연산세 수신자 대신 우편함을 명시
   - 수신자는 receive 연산에 송신자 대신 우편함을 명시
   - 두 프로세스 사이 통신 링크는 같은 우편함을 이용하는 경우 설정된다
   - 송신자가 여럿이고 수신자가 하나라면 우편함이 수신자에 속한 경우로 단방향, 수신 프로세스가 종료되면 우편함도 사라짐
   - 수신자가 여럿인 경우 우편함이 운영체제에 소속되어 한순간에 하나의 수신자만 우편함에서 메시지를 받을 수 있도록 운영체제가 수신자를 관리 -> 송신자와 수신자의 역할이 바뀔수도 있으므로 통신 링크는 양방향

---

프로세스가 자원을 사용하는 절차는

1. 프로세스가 필요한 자원이 있으면 요구
2. 자원을 획득한 후 사용 (획득하지 못하면 대기)
3. 사용이 끝나면 획득했던 자원을 해제하고 반납

# 교착상태

여러 개의 프로세스가 서로 상대방의 작업이 끝나기만 기다리고 있기에 결과적으로 어느 쪽도 영원히 진행하지 못하는 상태
-> 관련된 모든 프로세스가 자원획득의 가능성 없이 무한히 대기 상태인 것

- 기아 상태: 관련된 프로세스의 일부가 자원획득의 가능성은 있으나 계속적으로 대기 상태인 것

## 교착상태의 필요조건

1. 상호배제 조건
   - 프로세스가 자원에 대한 배타적인 통제권을 요구하는 조건
   - 적어도 하나 이상의 자원은 여러 프로세스에 의해 동시에 사용될 수 없음
   - 필요로 하는 자원을 다른 프로세스가 점유하고 있으면 반드시 대기하게 된다
2. 점유대기 조건
   - 프로세스가 이미 한 자원을 할방받아 점유하고 있는 상황에서 다른 프로세스가 점유하고 있는 또 다른 자원을 요청하여 해제되기를 기다리는 상황
3. 비선점 조건
   - 프로세스에 할당된 자원은 프로세스가 사용을 마치고 스스로 반환하기 전 해제되지 않음을 의미
   - 할당된 자원은 타의에 의해서 해제 되지 않는다
4. 환형대기 조건
   - 프로세스의 자원 점유 및 점유된 자원의 요구 관계가 환형을 이루며 대기하는 상황

## 자원할당 그래프

교착상태를 명확하게 표현하기 위해 자원할당 그래프를 이용

- V: 정점의 집합
  - P: n 개의 프로세스 {p1, p2, ... pn} => 원
  - R: m개의 단위자원 {r1, r2, ... rm} => 사각형 (단위 자원의 개수를 숫자로 표시)
- E: 방향 있는 간선의 집합
  - Q: 프로세스 p가 자원 r을 요구한다(요구간선)
  - S: 자원 r가 프로세스 p에 할당된다(할당간선)

1. 가용한 단위자원이 존재하면 요구간선은 할당간선으로 바뀐다
2. 자원이 해제될 때 이 할당간선은 삭제된다

3. 교착상태의 환형대기 조건을 만족하는 것은 사이클이 존재한다
4. 교착상태의 점유대기 조건을 만족하는 것은 한 프로세스에 할당간선과 요구간선을 연결하는 것이다
5. 교착상태의 비선점 조건을 만족하는 것은 요구간선으로 표현되는 것이다
6. 교착상태의 상호배제 조건을 만족하는 것은 할당간선으로 표현되는 것이다

7. 자원할당 그래프의 기본 성질로 점유대기, 비선점, 상호배제 조건으로 만족되므로 사이클의 유무로 교착상태의 발생 가능성을 확인할 수 있다

## 교착상태 예방

1. 상호배제 제거

- 공유할 수 있는 자원은 상호배제가 필요하지 않으므로 교착상태를 유발하지 않으나 공유할 수 없는 자원은 상호배제를 따른다
- 그러므로 상호배제 조건을 제거하여 교착상태를 예방하는 것은 불가능

2. 점유대기 제거

- 자원을 점유했을 때 대기하지 않도록 하거나 대기할 때 자원을 점유하고 있지 않도록 한다
- 자원을 점유했을 때 대기하는 상황이 발생하지 않도록 필요한 모든 자원을 처음에 한꺼번에 요구하여 할당받으면 된다
- 자원을 미리 점유하게 되어 실제 자원이 필요한 시점까지 아무도 그 자원을 활용하지 못해 자원이용률이 낮아질 수 있으므로 기아상태에 빠질 수 있다
- 점유 도중 해제할 수 없는 자원에는 적용할 수 없다

3. 비선점 제거

- 자원의 특성에 따라 선점 가능하도록 만들 수 없다
- 차선책으로 자원을 점유한 프로세스가 다른 자원을 요구할 때 대기가 발생한다면 할당받았던 자원을 모두 해제하여 다른 프로세스가 비선점 조건으로 대기할 가능성을 줄인다

4. 환형대기 제거

- 모든 자원에 일련번호를 지정하고 프로세스 자원을 요구할 때 일련번호를 기준으로 항상 오름차순이 되도록 요구하는 것이 환형대기를 제거할 수 있다
- 프로세스가 자원을 요구할 때 그보다 일련번호가 큰 자원은 점유하고 있지 않도록 하는 방법 또한 환형대기를 제거할 수 있다
- 점유대기 중인 프로세스는 항상 점유하고 있는 자원의 일련번호보다 대기 중인 자원의 일련번호가 클수밖에 없다
- 프로세스마다 자원의 요구순서가 다를 수 있으므로 자원의 일련번호 설정에 어려움이 존재

## 교착상태 회피

프로세스의 자원 사용에 대한 사전 정보를 활용하여 교착상태가 발생하지 않는 상태에 머물도록 하는 방법
(사전 정보: 현재 할당된 자원, 가용상태의 자원, 프로세스의 최대 요구량)

### 안전상태

교착상태를 회피하면서 각 프로세스에 그들의 최대 요구량까지 자원을 할당할 수 있는 상태
즉, 안전순서열이 존재하는 경우로, 안전순서열은 순서있는 프로세스의 집합으로 각 프로세스는 추가로 요구할 수 있는 자원의 양이 현재 가용상태의 자원으로 충당되거나 현재 가용상태인 자원에 할당된 자원까지 포함하여 충당 가능한 경우를 의미
그러므로 안전순서열이 존재하는 경우 어떤 프로세스가 당장 자원을 할당받지 못하더라도 안전순서열에서 자신보다 순서가 빠른 프로세스들이 수행 후 자원을 해제할 때까지 대기하면 결국 자원을 얻을 수 있는 것이다.

### 불안전상태

안전순서열이 존재하지 않는 경우, 다만 불안전상태라고 무조건 교착상태인 것은 아니다.

### 변형된 자원할당 그래프

각 자원의 단위자원이 하나밖에 없을 경우, 단위자원의 개수가 사라지고 선언간선이 추가된 것

- 선언간선은 프로세스가 언제일지 모르지만 앞으로 분명이 자원을 요구하게 될 것임을 나타냄, 요구간선과 동일하게 프로세스에서 자원으로 방향성을 지니므로 점선으로 표시

### 은행원 알고리즘

자원의 단위자원이 여러 개인 경우 은행원 알고리즘으로 교착상태를 회피할 수 있다. 자원을 요구받으면 그 자원을 할당해주고 난 후의 상태를 여러 데이터를 이용하여 계산해서 안전상태인지 확인한 후 안전상태가 보장되는 경우에만 자원을 할당한다.

- MAX : 프로세스의 각 자원에 대한 단위자원의 최대 요구량
- ALLOC: 프로세스의 현재 할당된 단위자원 개수
- NEED: 프로세스의 각 자원에 대한 추가 단위자원 요구량
  - MAX = ALLOC + NEED
- AVAL: 현재 가용한 각 자원의 단위자원의 수
- REQ: 프로세스가 자원을 k개 요구하는 상황
  - REQ <= NEED 이고 REQ <= AVAL 이면 오류도 없고 가용한 자원도 있는 경우이므로 할당해도 안전상태가 유지되는지 확인
  - REQ > NEED 거나 REQ > AVAL 이면 오류로 판단

""" 은행원 알고리즘
void bank(REQ) {
if (!(REQ) <= NEED) 오류;
if (!(REQ) <= AVAL) 프로세스 대기;

      ALLOC = ALLOC + REQ;
      NEED = NEED - REQ;
      AVAL = AVAL - REQ;

      status = safe(상태 데이터);
      if (state == true)
         REQ대로 할당; // 안전상태
      else
         프로세스 대기;
         상태 데이터 복구; // 불안전상태

}

boolean safe(상태 데이터) {
WORK = VAVL;
for (i = 1; i <= n; i++) FINISH[i] = false;
for (l = i; l <= n; l++) {
for (i = 1; i <= n; i++) {
if (FINISH[i] == false && NEED <= WORK) {
WORK = WORK + ALLOC;
FINISH[i] = true;
break;
}
}
if (i > n) break;
}
if (모든 i에 대해 FINISH[i] == true) return true; // 안전상태
else return false; // 불안전상태
}
"""

## 교착상태 탐지

교착상태를 탐지하면 교착상태를 해결하는 방법으로 쇼사니와 코프만 알고리즘을 수행한다.

### Shoshni and Coffman 알고리즘

은행원 알고리즘을 안전 알고리즘과 유사하나 현재 상태의 모든 자원 요구량을 고려하여 교착상태 여부를 확인

- 교착상태와 무관한 프로세스는 제외하기 위해 점유대기 조건에 해당하지 않는 ALLOC가 0인 프로세스는 초기화에서 FINISH를 true로 둔다
- 가용 가능한 자원량이 현재 요구량을 충족시켜 줄 수 있다면 역시 FINISH를 true 로 둔다
- 즉 FINISH가 false 인 프로세스가 존재한다면 교착상태로 판단한다

""" 교착상태 탐지 알고리즘
boolean detect(상태 데이터) {
WORK = AVAL;
for (i = 1; i <= n; i++) {
if (ALLOC != 0) FINISH[i] = false;
else FINISH[i] = true;
}

      for ( l = 1; l <= n; l++) {
         for (i = 1; i <= n; i++) {
            if (FINISH[i] == false && REQ <= WORK) {
               WORK = WORK + ALLOC;
               FINISH[i] = true;
               break;
            }
         }
         if (i > n) break;
      }
      if (FINISH[i] == false) return true; // 교착상태
      else return false; // 교착상태가 아님

}
"""

- 탐지 알고리즘은 O(mn^2) 시간에 수행되므로 자원 요구가 생길 때마다 수행하는 것은 비용이 크기 때문에 아래와 같은 때 시행한다
  - 즉시 받아들일 수 없는 자원 요구가 있을 때
  - 정해진 시간간격
  - CPU 효율이 일정 수준 이하로 떨어질 때

## 복구

- 오퍼레이터에게 교착상태가 발생했음을 알려 직접 수작업으로 처리
- 운영체제가 자동으로 교착상태로부터 복구
- 복구를 위한 프로세스를 선택할 때 복구 횟수를 고려하여 기아상태에 빠지지 않도록 해야 한다

### 교착상태 복구방법

1. 교착상태 프로세스를 종료
2. 교착상태 프로세스가 할당받은 자원을 해제하는 방법
   위와 같은 방법으로 환형대기를 없앨 수 있다

### 프로세스 종료

1. 모든 교착상태 프로세스 종료
   진행했던 내용에 대한 복원 비용이 큼
   프로세스의 우선순위, 진척도, 사용된 자원의 유형, 양 등 여러 요소 고려
2. 사이클이 제거될 때까지 프로세스를 하나씩 종료
   제거한 프로세스에 할당된 자원을 단계적으로 선점하여 이 자원을 다른 프로세스들에 할당
   프로세스의 진척도, 자원의 수, 복귀 시점 고려

# 프로세스와 메모리

- 프로세스가 동작하기 위해 CPU, 메모리, I/O장치, 파일 등의 자원을 할당받아야 하는데, 그중에서도 CPU와 메모리는 필수 요소이다.
- 프로세스가 실행 상태에서 동작은 프로그램 카운터(PC)를 참조하여 수행될 명령을 읽어와서 CPU의 해당 명령을 수행하는데 프로그램 카운터가 가리키는 주소라는 것이 결국 메모리상의 특정 위치가 된다.

- 새로운 프로세스를 언제 메모리에 둘 것인지 고려
- 다음에 실행될 프로세스를 메모리 내의 어느 곳에 둘건지 고려
- 메모리가 꽉 찬 상태에서 새로운 프로세스를 메모리에 적재해야 할 때 어떤 프로세스를 제거할 것인지 고려
- 고정 분할/동적 분할 고려
- 프로세스의 적재영역이 고정적/유동적인지 고려
- 메모리의 낭비를 줄이기 위해 많은 양의 프로세스를 메모리에 둘 것인지, 필요한 부분만 메모리 내에 둘 것인지 고려
- 자주 사용되지 않는 프로세스, 최근에 쓰이지 않는 프로세스가 무엇인지 등의 메모리 관리하기 위해 고려

## 기억장치의 계층구조

< 접근속도가 빠름/비트당 기억장치 비용이 높음 대용량 >
CPU(레지스터) <-> 캐시 메모리 <-> 메모리 <-> 보조기억장치

- 자주 실행되는 프로세스는 캐시에 두고 실행속도를 향상시킨다

## 환경

### 단일 프로그래밍 환경

오직 하나의 프로세스만 메모리를 전용으로 사용했기에 프로세스는 하나의 연속된 블록으로 메모리에 할당되는 연속 메모리 할당 방식을 이용

- 메모리 용량을 초과하는 프로세스는 실행될 수 없다
- 지속적으로 사용되지 않는 프로세스도 메모리에 적재되어 있어야 하므로 메모리 낭비가 심함
- 한 명의 사용자가 메모리를 전용하기에 대기하게 되어 자원의 낭비가 심함

### 다중 프로그래밍 환경

여러 개의 프로세스가 메모리에 동시에 적재되는 것

- 여러 메모리에 CPU 연산과 입출력을 나누고 동시에 실행되게 함으로써 시스템 처리량을 증가시킬 수 있다

## 메모리 분할

여러 프로세스를 메모리에 적재하기 위해 고안된 방법으로 하나의 분할에 하나의 프로세스가 적재되는 방식

### 고정 분할

메모리를 여러 개의 고정된 크기의 영역으로 분할하는 방식

- 내부 단편화: 프로세스의 크기가 적재된 분할영역의 크기보다 작아서 분할영역 내에 남게 되는 메모리는 결국 낭비

1. 각 분할 영역마다 큐를 두고 큐에 들어온 프로세스는 해당 분할 영역에만 적재되도록 하는 것
   - 프로그램 컴파일 시 프로그램 내의 주소를 절대주소로 번역하여 해당되는 특정 분할영역에만 적재되어야 하는 방식
   - 구현이 용이하나 큐가 빈 분할이 있어도 다른 큐의 프로세스는 적재할 수 없어서 효율성이 낮다
2. 메모리 전체에 하나의 큐만 두고 모든 프로세스를 하나의 작업 큐에 넣어서 어느 분할에서든지 실행 가능하게 하는 것
   - 컴파일 시 프로그램 내 주소를 상대 주소로 번역하여 어디든 적재가 가능한 방식
   - 기억장치의 낭비를 줄이지만 재배치 가능 번역기와 로더는 절대번역기보다 더 복잡하다

### 동적 분할

각 프로세스에 필요한 만큼의 메모리만 할당하는 방식

- 외부 단편화: 메모리 할당과 반환이 계속 반복됨에 따라 작은 크기의 공백이 메모리 공간에 흩어져 생기는 것
  - 통합: 인접된 공백을 더 큰 하나의 공백으로 만드는 과정
  - 집약: 메모리 내의 모든 공백을 하나로 모으는 작업
- 내부 단편화 X

## 메모리 보호

연속 메모리 할당 방식에서는 프로세스가 사용할 수 있는 주소 범위를 하한-상한 레지스터 쌍 또는 하한-크기 레지스터 쌍으로 제한하여 다른 할당영역을 침범하지 않게 한다
이 때 프로세스가 제한을 넘어 운영체제를 호출하면 시스템 호출을 통해서만 가능하다

## 메모리 배치

동적 분할 다중 프로그래밍에서 새로 반입된 프로그램이나 데이터를 메모리의 어느 위치에 배치할 것인가 결정하는 것

1. 최초 적합
   빈 공간 리스트를 메모리의 주소순으로 유지하여 프로세스가 적재될 수 있는 빈 공간 중에서 가장 먼저 발견되는 곳에 할당

2. 후속 적합
   이전 탐색에 끝난 그 다음부터 시작하여 사용 가능한 빈 공간 중에서 가장 먼저 발견되는 곳에 할당

3. 최적 적합
   큰 빈 공간을 최대한 많이 남겨 놓기 위한 방법으로 필요한 공간을 빈 공간 중에서 가장 작은 곳을 선택하여 할당

4. 최악 적합
   필요한 공간을 제공할 수 있는 빈 공간 중 가장 큰 곳을 선택하여 할당
   이는 작은 공간이 남아 사용하지 못하는 공간이 발생하는 것을 최소화하기 위한 방법

# 가상 메모리

컴퓨터 시스템의 메모리 크기보다 더 큰 기억 공간이 필요한 프로세스를 실행할 수 있게 하는 방법

- 실행 중인 프로세스에 의해 참조되는 주소를 메모리에서 사용하는 주소와 분리하는 것

* 가상 주소: 실행 프로세스가 참조하는 주소
* 실주소/물리적 주소: 실제 메모리에서 사용하는 주소

* 가상주소 공간: V, 실행 프로세스가 참조하는 가상주소의 범위
* 실주소 공간: R, 사용 가능한 실주소의 범위
  프로세스는 가상주소만 참조하지만 실제로 메모리에서 실행되어야 하므로 프로세스가 실행되면 가상주소는 실주소로 변환되어야 하므로 운영체제에서 사상(mapping)이 된다

## 동적 주소변환(DAT)

프로세스가 실행되는 동안 가상주소를 실주소로 바꾸는 절차
프로세스의 가장주소 공간에서 연속적인 주소가 실주소 공간에서도 연속적일 필요는 없다는 인위적 연속성을 가지고 있다

## 블록 단위 주소변환

동적 주소변환(DAT) 방식은 가상 메모리에서 위치가 현재 메모리의 어디에 위치하는지 나타내는 주소변환 사상표를 유지해야 한다

주소변환이 가상주소 내 각 항목별로 바이트나 워드 단위로 이루어지다면 변환에 필요한 정보량이 너무 많아져서 프로세스가 요구하는 메모리 공간보다 사상표가 더 큰 메모리 공간이 필요하게 되므로 가상 메모리를 효율적으로 구현하려면 사상정보의 양을 줄여야 하므로 항목대신 블록 단위로 주소변환이 이루어지는 방식을 블록 단위 주소변환이라 한다

### 블록 사상 시스템

각 블록이 메모리의 어디에 위치하는지 관리
가상주소 = (블록번호, 변위) => v = (b, d)

1. 블록: 특정 항목을 참조하기 위해 그 항목이 들어있는 곳
2. 변위: 블록의 시작 부분으로부터 항목까지 위치

- 블록 크기가 커질수록 사상정보 저장에 필요한 메모리의 양은 작아지는 대신 블록을 보조기억장치에서 메모리로 이동시키는데 필요한 전송시간이 늘어나고 한 블록이 차지하는 메모리 공간이 커져서 메모리를 공유할 수 있는 프로세스의 수가 줄어든다

### 페이징 기법

페이지: 가상 메모리의 크기가 동일한 블록
가상주소 = (페이지번호, 변위) => v = (p, d)
ex) 3번 페이지 안, 8byte 만큼 떨어져 있다면 v=(3, 8)이 되어 페이지의 크기가 1024byte 일 때 1024\*3 + 8 = 3080 이 된다

- 프로세스 사이 메모리 보호는 페이지 단위로 이뤄짐
- 메모리도 동일 크기의 페이지 프레임으로 나뉘어 사용
- 외부 단편화가 아닌 페이지 내부에 내부 단편화가 발생

#### 페이지 프레임

프로세스가 실행되기 위해 특정 페이지를 참조하려면 해당 페이지는 메모리상에 위치해야 한다. 그러므로 메모리 영역도 가상 메모리와 동일하게 고정된 크기의 블록으로 나누어 두고 각 블록을 페이지 프레임이라고 한다. 페이지 프레임 아무 곳에 페이지가 적재된다.

#### 페이지 사상표

페이지가 메모리에 적재된 후 바로 찾을 수 있도록 프로세스가 사용하는 가상주소를 실주소로 동적 변환 할 수 있어야 한다.
이때 페이지 사상표를 이용하여 가상주소의 페이지 번호에 대한 실주소의 페이지 프레임 번호가 저장되어 있으므로 실주소로 동적 변환한다.

1. 직접사상: 페이지 사상표를 직접 이용하여 동적 주소변환을 하는 것
2. 연관사상: 페이지 변환 정보를 연관 메모리에 저장한 연관사상표를 이용하여 동적 주소변환을 하는 방식
   - 연관 메모리: 저장된 값을 이용하여 데이터를 액세스하는 고속 메모리 장치
     실제로는 직접사상과 연관사상을 같이 사용하여 연관사상표에는 가장 최근 참조된 페이지 항목만 보관하고 나머지는 페이지 사상표에 수록하여 연관사상표에 없을 때만 직접사상을 이용하도록 구현한 것

### 세그먼테이션 기법

세그먼트: 모듈화에 따른 논리적 의미에 부합하는 다양한 크기의 블록
가상주소 = (세그먼트번호, 변위) => v = (s, d)
세그먼트를 메모리에 적재하려면 수용할 수 있을 만큼 충분히 큰 메모리의 사용 가능한 영역에 놓는다. (최초적합/최적적합과 동일)

#### 세그먼트 사상표

해당 세그먼트가 현재 메모리에 존재하는지 여부를 나타내는 비트값과 보조기억장치에서의 위치정보, 세그먼트의 길이(세그먼트 오버플로를 확인) 등이 저장되어 있다.

### 페이징/세그먼테이션 혼용 기법

세그먼테이션 기법의 논리적 장점과 페이징 기법의 메모리 관리 측면의 장점을 활용하기 위한 기법
각 세그먼트를 다시 페이지 단위로 분할하고 메모리도 페이지 프레임으로 분할하여 하나의 페이지만 페이지 프레임에 적재하는 방식
가상주소 = (세그먼트번호, 페이지번호, 변위) => v=(s, p, d)

1. 가장 최근에 참조된 페이지는 연관사상표에 있으므로 우선 연관메모리에서 (s, p)를 찾기 위한 탐색이 이루어진다
2. p에 의한 페이지 프레임이 d와 합하여 v=(s, p, d)에 대응하는 실주소를 생성한다
3. 연관사상표에 없는 경우 직접사상 변환은 메모리의 세그먼트 사상표의 시작주소 b가 세그먼트 번호 s와 더해져 세그먼트 사상표의 항목주소 b+s를 생성한다

## 메모리 호출 기법

어느 시점에 페이지/세그먼트를 메모리에 적재할지 결정하는 기법

### 요구 페이지 호출기법

한 프로세스의 페이지 요구가 있을 때 요구 페이지를 메모리에 적재하는 방법
각 페이지는 실행 중인 프로세스에 의해 명백히 참조될 때에만 보조기억장치에서 메모리로 옮겨진다

- 오버헤드 최소화
- 페이지 부재 발생
- 옮겨진 페이지는 모두 프로세스에 의해 실제로 참조된 것

### 예상 페이지 호출기법

현 시점에서 액세스되고 있지 않지만 곧 사용될 것으로 예상되는 페이지를 미리 메모리에 옮겨 놓는 방법

- 예상이 옳았다면 실제로 필요한 시점이 되었을 때 프로세스의 실행이 단절되지 않아 실행시간이 감소
- 예상이 잘못된 경우에는 예상 적재에 따른 시간과 메모리 낭비 발생

## 페이지 교체 알고리즘

페이징 기법에서는 모든 페이지 프레임이 사용되고 있는 것이 일반적이므로 메모리에 새로 적재되어야 할 페이지를 위해 적절한 교체 대상 페이지 프레임을 선택하여 그 내용을 보조기억장치에 보관된 후 새로운 페이지를 적재해야 한다

- 최적화 원칙: 페이지 프레임에 있는 페이지 중 이후로 가장 오랫동안 사용되지 않을 페이지를 교체 대상으로 선택 => 미래를 예측할 수 없으므로 실제 구현은 불가하나 시간 및 공간의 오버헤드가 적은 방법을 선택

### 교체가 일어나지 않아야 하는 페이지 종류

1. 페이징을 위한 커널 코드 영역
2. 커널에 속하지 못한 보조기억장치 드라이버 영역
3. 시간을 맞춰 동작해야 하는 코드 영역
4. DMA(Direct Memory Access) 등에 의해 입출력장치로부터 직접 데이터가 교환되어야 하는 데이터 버퍼 영역

### FIFO 페이지 교체

First In First Out => 큐 이용 (페이지 추가 시 trail에, 페이지 교체 대상은 head)
메모리 내 가장 오래 있었던 페이지를 교체 대상으로 선택하여 교체
다만 실제로 메모리에 가장 오랫동안 있었던 페이지는 앞으로도 계속 사용될 가능성이 높기에 가장 많이 쓰는 페이지를 교체시킬 가능성이 있다

- Belady 이상현상: 프로세스에 더 많은 수의 페이지를 할당할 경우 오히려 페이지 부재가 더 많이 발생할 수 있다는 것

### LRU 페이지 교체

Least Recently Used
메모리 내 가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택으로 교체

- 국부성 휴리스틱: 최근의 상황이 가까운 미래에 대한 좋은 척도
- 국부성(locality): 프로세스는 기억장치 내의 정보를 균일하게 액세스하는 것이 아니라 어느 한순간에 특정 부분을 집중적으로 참조

1. 시간 국부성: 처음 참조된 기억장소가 가까운 미래에도 계속 참조될 가능성이 높다
2. 공간 국부성: 하나의 기억장소가 참조되면 그 근처의 기억장소가 계속 참조되는 경향이 있다

- Belady의 이상현상이 발생하지 않고 최적화 원칙에 맞는 선택이 가능하지만 경험적 판단이 맞지 않는 상황도 존재할 수 있다
- 리스트, 참조시간을 위한 테이블 등 막대한 오버헤드를 초래

#### LRU 페이지 교체 알고리즘 구현 방식

1. 참조시간 이용
   각 페이지 참조될 때마다 그때의 시간을 기록하여 교체가 필요한 경우 참조시간이 가장 오래된 페이지가 교체 대상으로 선택된다

2. 리스트 이용
   리스트를 이용하여 페이지를 액세스하면 해당 페이지 번호를 리스트의 선두에 옮겨 교체가 필요한 경우 리스트의 끝에 있는 페이지가 교체 대상으로 선택된다

### LFU 페이지 교체

Least Frequency Used
페이지가 얼마나 많이 사용되었는지에 착안한 방법
메모리 내 참조된 횟수가 가장 적은 페이지를 교체 대상으로 선택하여 교체한다

- 가장 드물게 이용되는 페이지가 가장 최근에 메모리로 옮겨진 페이지일 가능성이 있다
- 초기에 많이 사용된 후 더이상 사용되지 않는 페이지는 교체 대상에서 제외됨으로써 불필요하게 메모리를 점유할 가능성이 있다
- 참조 횟수를 기록하고 가장 적은 참조 횟수를 찾는 것은 오버헤드가 크다

### 2차 기회 페이지 교체

참조 비트가 0이면서 메모리 내 가장 오래 있었던 페이지를 교체 대상으로 선택하여 교체
이때 자주 참조되는 페이지에 교체되지 않고 메모리에 남아있게 해줄 수 있는 2차 기회를 참조 비트를 준다

- 참조 비트: 페이지 프레임에 있는 페이지마다 부여된 값 (처음 적재될 때 0, 이후로 해당 페이지가 참조되면 1)

* 큐가 꽉 찬 경우에만 삭제가 발생하기 때문에 하나의 포인터만으로 구현 가능
* 포인터는 항상 마지막에 추가된 페이지의 다음 위치를 가리킨다 (페이지 프레임이 꽉 차지 않았다면 포인터는 빈칸을 가리킴)

### 클럭 페이지 교체

2차 기회 페이지 교체에서 큐를 변형된 원형 큐로 관리하는 경우
원형 큐가 시곗바늘이 돌아가는 것처럼 관리되므로 구현 시 원형 큐의 형태로 앞 뒤의 위치를 head, tail 포인터로 관리

## 프로세스별 페이지 집합 관리

각 프로세스가 사용할 수 있는 페이지 프레임의 개수를 프로세스별 페이지 집합이라 하며, 이는 컴퓨터 시스템의 성능에 영향을 준다

- 집합 크기가 작을수록 메모리에 적재할 수 있는 프로세스의 수는 많아져서 시스템 처리량이 증대될 수 있지만 페이지 부재는 자주 발생하게 된다

### 페이지 집합을 관리하는 알고리즘

1. 워킹 세트 알고리즘
   페이지 부재비율을 감소시키기 위해 데닝이 제안한 모델

- 워킹 세트는 한 프로세스가 최근에 참조한 페이지의 집합으로 W(t, d)는 시각 t에 t를 포함한 직전 d시간 동안 참조한 페이지의 집합
  - d는 워킹 세트의 window 크기
  - t-d+1 부터 t까지 참조한 페이지의 집합
  - 윈도 크기가 고정되어 있어도 워킹 세트의 크기는 달라질 수 있음
- 프로세스가 효율적으로 수행되기 위해 프로세스의 워킹 세트가 메모리 내 유지되어야 함, 즉 프로세스마다 워킹 세트의 크기에 맞게 페이지 프레임의 개수를 조절함
- 워킹 세트가 메모리 내 유지되지 않으면 보조기억장치로부터 계속해서 페이지를 요구하게 되므로 쓰레싱이 유발됨
  - 쓰레싱: 페이지 부재가 비정상적으로 많이 발생하여 프로세스 처리보다 페이지 교체처리에 많은 시간을 소비하여 시스템 처리량이 급격히 저하되는 현상
- 워킹 세트를 정확히 알아서 업데이트 하는 것이 현실적으로 어려움
- 윈도 크기 d의 최적값을 알기 어려움

2. PFF 알고리즘
