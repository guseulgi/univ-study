# 운영체제란

대표적인 시스템 소프트웨어

## 운영체제의 역할

1. 자원 관리로 컴퓨터 시스템을 효율적으로 운영하는 것

- 하드웨어 자원
- 소프트웨어 자원

2. 사용자 지원
   운영체제는 사용자가 내린 명령을 해석하여 실행하며 사용자와 하드웨어 사이의 매개체 역할을 하면서 사용자에게 편의성을 제공

## 모드

1. 커널 모드
   하드웨어를 직접 제어할 수 있는 CPU의 명령어를 사용할 수 있는 모드
1. 일체형 커널
   운영체제의 모든 서비스가 커널 내에 포함된 커널
1. 마이크로커널
   운영체제 요소의 대부분을 커널 외부로 분리하여 커널 내부에는 메모리 관리, 프로세스 간 통신, 멀티태스킹 등 최소한 요소만 남겨 놓은 커널

1. 사용자 모드(보호 모드)
   하드웨어를 직접 제어할 수 있는 CPU의 명령어를 사용할 수 없는 모드

- 커널 모드에서는 운영체제만 동작하므로 응용 프로그램은 사용자 모드에서만 동작한다
- 시스템 호출: 응용 프로그램이 하드웨어에 대한 제어가 필요한 경우 운영체제에 서비스를 요청하는 메커니즘

## 운영체제의 구성

1. 프로세스 관리자

- CPU를 할당하기 위한 스케줄을 결정
- 프로세스의 상태를 관리

2. 메모리 관리자

- 메모리 할당 및 회수
- 운영체제가 직접 사용하는 메모리 공간에 응용 프로그램의 프로세스가 접근하지 못하도록 해야함

3. 장치 관리자

- 컴퓨터 시스템의 모든 장치를 관리

4. 파일 관리자

- 프로그램 파일과 데이터 파일을 관리
- 저장장치의 공간과 파일의 생성, 수정 등의 접근 제한도 관리

## 운영체제의 유형

1. 일괄처리 운영체제
   작업을 모아서 순서대로 처리하는 방식

2. 시분할 운영체제
   사용자의 프로그램을 한번에 조금씩 수행하여 여러 프로그램이 동시에 실행되는 것과 비슷한 효과를 내는 방식
   요청한 시점부터 반응이 시작되는 시점까지의 소요시간을 의미하는 응답시간이 일괄처리 운영체제보다 크게 단축됨

3. 실시간 운영체제
   원하는 시간 내에 프로그램의 결과를 얻을 수 있는 운영체제
   즉 처리기한을 맞추는 것이 중요한 우선순위가 높은 작업을 우선 처리할 수 있는 기법 활용

4. 분산 운영체제
   네트워크를 통해 다른 컴퓨터 시스템의 자원을 이용하는 것이 자신의 컴퓨터 시스템에 있는 자원을 이용하는 것처럼 가능하도록 함

---

# 프로세스

실행 중인 프로그램

- 프로그램은 디스크 내 파일로 존재하는 동작하지 않는 정적이며 수동적인 개체
- 프로세스는 프로그램을 실행시킨 것으로 운영체제로부터 프로그램이 동작을 하는데 필요한 CPU, 메모리, 입출력장치, 파일 등의 자원을 할당받아 동작을 시작한 것, 능동적인 개체
- 하나의 메모리 구조를 갖고 그 안의 코드 영역에 대해 하나의 제어 흐름을 가짐 -> 코드 영역, 정적 데이터 영역, 스택 영역, 힙 영역
- 프로그램 카운터가 가리키는 명령을 처리하는데 하나의 프로세스는 하나의 PC만 유지하므로 제어 흐름을 하나만 갖기 때문에 기본적으로 다중 처리가 불가능하다는 특징이 있다.

## 프로세스의 구성

- 메모리 구조
- 코드 영역: 프로그램 자체
- 데이터 영역
- 정적 데이터: 상수, 전역변수
- 스택: 지역변수, 매개변수
- 힙: 동적
- 프로세스 제어 블록(PCB): 프로세스의 정보를 보관

- PID: 프로세스 식별자
- PC(프로그램 카운터): 다음에 실행할 명령의 주소
- 상태
- 레지스터
- 프로세스 우선순위
- 메모리 관리 정보: 프로세스가 저장된 주소와 가상 메모리의 실주소의 사상 정보 등
  운영체제는 보통 여러 프로세스를 동시에 관리하며 번갈아 실행시키게 된다. 실행 중이던 프로세스의 정보를 PCB에 저장한 후 나중에 이 프로세스를 다시 실행하게 되면 프로세스 제어 블록에 저장된 정보를 이용하여 이어서 실행한다.

## 프로세스 상태 관리

1. 생성: 처음 작업이 주어진 상태로 프로세스 제어 블록을 생성하고 작업 큐에 넣는다.
2. 준비: 프로세스의 메모리 구조가 생성되어 CPU 할당을 기다리는 상태로 준비 큐에 머물다가 CPU를 할당받으면 실행 상태로 전이된다.
3. 실행: 프로세스가 처리되는 상태, CPU를 할당하는 과정을 디스패치라고 한다.

- 스케줄러가 준비 큐에서 다른 프로세스를 선택하게 되면 실행 상태의 프로세스는 CPU를 회수당하고 준비 상태로 전이된다.
- 실행 상태 프로세스가 입출력을 요구하는 작업이나 페이지 교환을 요구하는 작업을 만나면 대기 상태로 전이된다. (이러한 작업은 상대적으로 오랜 시간이 걸리기 때문에 CPU를 다른 프로세스에 할당하여 활용하기 위함)

4. 대기: 프로세스가 I/O 작업이 끝날 때까지 특정 자원을 할당 받을 때까지 보류되는 상태
5. 종료: 프로세스가 더 이상 실행되지 않도록 끝난 상태

## 부모 프로세스/자식 프로세스

한 프로세스가 다른 프로세스를 생성하는 방법 -> 프로세스 생성 시스템 호출

1. 부모 프로세스: 시스템 호출을 하는 프로세스
2. 자식 프로세스: 시스템 호출을 통해 새로 생성된 프로세스

- UNIX, Linux

  - fork() 시스템 호출을 통해 부모 프로세스의 복제본인 자식 프로세스 생성 (부모 프로세스의 메모리 구조와 동일)
  - exec() 을 사용하면 자식 프로세스가 부모 프로세스와 다른 프로그램을 실행함

- Windows
  - CreateProcess() 시스템 호출 사용, 이는 처음부터 새로운 프로그램으로 자식 프로세스를 생성

## 프로세스 종료

- 일반적인 경우: 프로세스의 마지막 명령이 실행을 마쳐 모든 처리를 완료하고 정상적으로 종료
- 부모 프로세스가 자식 프로세스의 번호를 이용하여 프로세스 종료 시스템 호출로 종료
- 부모 프로세스가 종료되는 경우 운영체제에 의해 자식 프로세스들이 모두 종료

다만 자식 프로세스가 종료되어 자원이 회수되더라도 자식 프로세스의 프로세스 제어 블록(PCB)은 부모 프로세스가 결과를 받을 때까지 사라지지 않고 유지 된다.

---

# 쓰레드

프로세스 내에서 다중 처리를 위해 제안된 개념
(자원 소유의 단위는 프로세스, 디스패칭의 단위는 쓰레드)

- 쓰레드마다 프로그램 카운터(PC)가 있어 쓰레드별로 디스패칭이 가능 (+레지스터, 스택)
- 각 쓰레드는 실행에 필요한 최소한의 정보만 가짐 (그 외 정보는 프로세스에 두고 다른 쓰레드와 공유)
- 쓰레드 또한 프로세스처럼 생성, 준비, 실행, 대기, 종료상태를 가짐

---

# 프로세스 스케줄링

1. 상위단계 스케줄링(장기 스케줄링)
   시스템에 들어와 작업 큐에 있는 작업을 선택하여 프로세스를 생성한 뒤 프로세스 준비 큐에 전달
   - 입출력 중심 작업/연산 중심 작업을 균형있게 선택하도록 작업순서 결정
2. 중간단계 스케줄링(중기 스케줄링)
   프로세스를 일시적으로 메모리에서 제거하여 중지시키거나 중지된 프로세스에 다시 메모리를 할당하여 활성화시켜 시스템에 대한 단기적인 부하를 조절하는 역할
   - 시스템이 과부하되는 경우 메모리에서 어떤 프로세스를 제거해야 시스템의 부하가 줄어들지를 결정하여 실제로 중지시켜준다
3. 하위단계 스케줄링(단기 스케줄링)
   준비큐에 있는 프로세스를 선택하여 사용 가능한 CPU를 할당하는 역할

## 스케줄링의 목표

1. 공정성: 모든 프로세스가 적정 수준에서 CPU 작업을 할 수 있게 하는 것
2. 균형성: 시스템의 자원들이 충분히 활용될 수 있게 하는 것

### 목표 기준

1. 처리량(throughput): 주어진 시간에 처리한 프로세스 수
2. 반환시간(turnaround time): 프로세스 생성 시점부터 종료 시점까지의 소요시간
3. 응답시간(response time): 요청한 시점부터 반응이 시작되는 시점까지의 소요시간
4. 대기시간(waiting time): 프로세스가 종료될 때까지 준비큐에 기다린 시간의 합

### 일괄처리 운영체제 목표

처리량의 극대화, 반환시간의 최소화, CPU 활용의 극대화

### 시분할 운영체제 목표

빠른 응답시간, 과다한 대기 시간 방지

### 실시간 운영체제 목표

처리기한 맞추기

## 스케줄링 정책(하위단계 스케줄링)

1. 선점 스케줄링 정책

- 실행 중인 프로세스에 인터럽트를 걸고 다른 프로세스에 CPU를 할당할 수 있는 스케줄링 방식
- 높은 우선순위의 프로세스를 우선 처리해야 하는 경우 유용
- 컨텍스트 스위칭이 일어나며 오버헤드 발생
  - 컨텍스트란 CPU의 모든 레지스터와 운영체제에 따라 요구되는 프로세스의 상태
  - 컨텍스트 스위칭은 CPU가 현재 실행하고 있는 프로세스의 문맥을 프로세스 제어 블록에 저장하고 다른 프로세스의 프로세스 제어 블록으로부터 문맥을 복원하는 작업

2. 비선점 스케줄링 정책

- 실행 중인 프로세스를 바로 준비상태로 전이시킬 수 없는 스케줄링 방식
- CPU를 할당받아 실행이 시작된 프로세스는 대기/종료상태로 전이될 때까지 계속 실행상태에 있게 된다

## 스케줄링 평가 기준

1. 평균대기시간: 각 프로세스가 수행이 완료될 때까지 준비큐에서 기다리는 시간의 합의 평균값
2. 평균반환시간: 각 프로세스가 생성된 시점부터 수행이 완료된 시점까지의 소요시간의 평균값
   - 프로세스 생성 시간과 대기상태에서의 시간도 모두 포함

## 스케줄링 알고리즘

1. 비선점 방식

   1. FCFS 스케줄링
      프로세스는 준비 큐에 도착한 순서에 따라 디스패치되며 한 프로세스가 CPU를 차지하면 그 프로세스의 수행이 완료된 후 다음 프로세스가 CPU를 차지하고 수행된다

      - 프로세스들의 도착순서에 따라 평균반환시간이 크게 변함
      - 우선순위에 따른 프로세스를 처리하는 방법이 최근 사용되는데, 그 중에서도 우선순위가 같은 경우 FCFS를 적용

   2. SJF 스케줄링 (Shortest Job First)
      준비 큐에서 기다리는 프로세스 중 실행시간이 가장 짧다고 예상되는 것을 먼저 디스패치하여 실행

      - CPU 사이클이 미리 주어져야만 적용 가능 (미리 예상 불가)
      - 실행예정시간의 길이를 사용자 추정에 의존
      - 비선점이므로 새로 들어온 짧은 작업이 실행 중인 긴 작업을 기다리게 되기도 하므로 시분할 운영체제나 실시간 운영체제는 적합하지 않음

   3. HRN 스케줄링 (Highest Response Ratio Next)
      준비 큐에서 기다리는 프로세스 중 응답비율이 가장 큰 것을 먼저 디스패치하여 실행
      - 응답비율 = (대기시간+예상실행시간) / 예상실행시간
      - 응답비율은 예상실행시간이 짧고 대기시간이 길수록 커짐, 즉 모든 프로세스가 동시에 준비 큐에 들어온다면 예상실행시간이 가장 짧은 프로세스가 선택되고 예상실행시간이 모두 동일한 프로세스지만 준비큐에 들어온 시각이 모두 다르다면 대기시간이 가장 긴 프로세스가 선택됨

2. 선점 방식

   1. SRT 스케줄링 (Shortest Remaining Time)
      준비 큐에서 기다리는 프로세스 중 남은 실행시간이 가장 짧다고 예상되는 것을 먼저 디스패치하여 실행

      - 실행예정시간의 길이를 사용자 추정에 의존
      - 실행되는 각 프로세스의 실행시간을 추적하여 각 프로세스가 서비스를 받은 시간을 기록해야 하며, 선점을 위한 컨텍스트 스위칭도 해야 하므로 오버헤드가 SJF보다 크다

   2. RR 스케줄링 (Round Robin)
      프로세스가 도착한 순서대로 프로세스를 디스패치하지만 정해진 시간 할당량(시간각격)에 의해 실행을 제한

      - 시분할 운영체제에 적합
      - 시간 할당량을 어떻게 정하느냐에 따라 성능이 크게 달라진다
      - 프로세스가 한 번에 처리할 양을 처리할 수 있는 정도가 적당

   3. 다단계 피드백 큐 스케줄링
      입출력 중심인 프로세스와 연산 중심인 프로세스의 특성에 따라 서로 다른 시간 할당량을 부여
      - n 개의 단계가 있는 경우, 각 단계마다 하나씩의 준비큐가 존재하고 단계가 커질수록 시간 할당량은 커지는 형태
      - 하나의 단계에서 디스패치가 일어나면 다른 단계에선 디스패치 불가
      - 연산 위주의 프로세스는 시간 할당량 안에 종료되지 못하고 점점 단계가 커지고, 입출력 위주의 프로세스는 시간 할당량보다 짧은 실행이 유지되어 작은 단계를 유지한다

---

# 병행 프로세스

## 병행성

여러 개의 프로세스나 쓰레드가 동시에 수행되는 시스템의 특성

## CPU 개수

- 인터리빙 방식: CPU 1개에서 병행 프로세스가 실행되는 경우
  - 한순간에 하나의 프로세스가 실행
- 병렬처리 방식: 여러 개의 CPU(멀티프로세서) 시스템
  - 메모리 구조에 따라 실행되는 형태가 차이남
  - 강결합 시스템에서는 여러 CPU가 하나의 기억장치를 공유 (master/slave 환경, SMP-Symmetric MultiProcessing)
  - 약결합 시스템에서는 2개 이상의 독립된 컴퓨터 시스템이 네트워크로 서로 연결된 형태 즉 각 시스템은 자신의 운영체제와 기억장치를 가지고 독자적으로 운영
  - 시스템 간 통신을 위해 메시지 전달이나 원격 프로시저 호출(IPC) 사용

## 독립 프로세스

수행 중인 다른 프로세스에 영향을 주지 않고 받지도 않는 프로세스

- 자신이 사용하는 데이터를 다른 프로세스와 공유 X
- 결정적
- 재생 가능
  => 다른 프로세스의 영향을 받지 않으므로 입력 데이터만 동일하다면 실행결과는 항상 동일

## 협력 프로세스

수행 중인 다른 프로세스와 영향을 주고받으며 동작하는 프로세스

- 다른 프로세스와 데이터와 상태를 공유
- 비결정적
- 재생 불가
  => 다른 프로세스의 영향을 받을 수 있으므로 입력 데이터가 동일하더라도 실행 결과가 달라질 수 있음

---

# 병행성 문제

## 상호 배제

2개 이상의 프로세스가 동시에 임계영역을 수행하지 못하도록 하는 것

### 임계영역

2개의 프로세스가 동시에 사용하면 안되는 공유자원을 액세스하는 프로그램 코드 영역

## 동기화

2개 이상의 프로세스에 대한 처리순서를 결정하는 것

## 프로세스 간 통신 (IPC)

프로레스들이 데이터를 공유하기 위해 반드시 필요한 것

1. 변수 사용
2. 메시지 송수신

---

# 세마포어

상호배제와 동기화 문제를 해결하기 위한 도구

- 정수형 공용변수
- 사용 가능한 자원의 수, 잠김이나 풀림의 상태값 등의 초기화 필요
- P, V연산의 기본연산만 사용, 해당 연산은 인터럽트 되지 않고 하나의 단위로 처리됨

"""
void P (semaphore s) {
if (s > 0) s--;
else 현재 프로세스를 대기시킴;
}

void V (semaphore s) {
if (대기 중인 프로세스 없음) s++;
else 대기 중인 프로세스 1개 진행;
}
"""

## 상호배제 해결

한 프로세스가 임계영역을 수행 중이라면 다른 프로세스는 임계영역에 진입해서 안되며, 임계영역을 수행 중이던 프로세스가 임계영역에서 벗어나면 대기 중인 프로세스 중 하나는 새로이 임계영역을 수행해야 한다.

- 진입영역 -> P 연산
- 해제영역 -> V 연산
- 세마포어 초기값 1: 수행 시작 가능 여부

## 동기화 해결

A 프로세스가 S1를 수행한 뒤 B 프로세스 S2 를 수행하도록 동기화 하려면 S2 앞에 P 연산을 두고 S1 뒤에 V 연산을 두어 동기화할 수 있다.

- 세마포어 초기값 0: S1이 아직 수행되지 않음을 의미

---

# 병행 프로세스

## 생산자-소비자 문제 (유한 버퍼 문제)

두 협력 프로세스 사이 버퍼를 두고 한쪽 프로세스는 데이터를 넣고, 다른 프로세스는 데이터를 꺼내는 상황을 다루는 문제

## 생산자-소비자 문제 조건

1. 버퍼에 여러 프로세스가 동시에 접근 불가
2. 버퍼의 크기가 유한함
   => 상호배제와 동기화가 필요

## 세마포어를 이용한 해결

- mutex = 1 => 상호배제
  - 생산자가 버퍼에 데이터를 넣는 부분과 소비자가 버퍼에서 데이터를 꺼내는 부분은 임계영역이 된다
- empty = n (버퍼 수) => 동기화
  - 버퍼가 가득 찼을 때, 버퍼에 존재하는 빈 공간의 개수를 의미
  - 생산자가 데이터를 생산하더라도 소비자가 버퍼에서 데이터를 꺼낸 후에야 버퍼에 데이터를 넣을 수 있다
- full = 0 => 동기화
  - 버퍼가 빈 경우, 데이터의 개수를 의미
  - 소비자가 사용할 데이터가 없다면 생산자가 버퍼에 데이터를 넣은 후에야 소비자가 버퍼에서 데이터를 꺼낼 수 있다

---

# 판독기-기록기 문제

여러 협력 프로세스가 파일 같은 공유자원을 사이에 두고 데이터를 쓰거나 데이터를 읽는 상황을 다루는 문제

## 판독기-기록기 문제의 구체적인 조건

1. 기록기가 공유자원에 데이터를 쓰는 중에 다른 기록기나 판독기는 공유자원에 접근할 수 없다 => 상호배제 필요
2. 여러 판독기는 동시에 공유자원에서 데이터를 읽을 수 있다

## 제1판독기-기록기 문제

판독기가 공유자원에 접근 중이라면 기록기보다 판독기에 우선순위를 주는 것

- 대기 중인 기록기가 있든 없든 새로운 판독기는 즉시 공유자원에 접근할 수 있다
- 기록기가 기아상태에 빠질 수 있다
  - 기아상태: 프로세스가 필요한 자원을 할당받지 못하고 계속적으로 대기하게 되는 상황

## 제2판독기-기록기 문제

판독기가 공유자원에 접근 중이라면 판독기보다 기록기 우선순위를 주는 것

- 대기 중인 기록기가 있으면 새로운 판독기는 두번째 조건에도 불구하고 공유자원에 접근할 수 없다
- 기록기의 기아상태를 방지하지만 판독기의 병행성이 떨어지거나 판독기가 기아상태에 빠질 수 있다

## 세마포어를 이용한 해결

1. 제1판독기-기록기 문제

   - wrt = 1 (세마포어)

     - 기록기에 대한 상호배제
     - 기록기가 공유자원에 데이터를 쓰는 부분은 다른 기록기가 쓰거나 판독기가 읽는 부분과 동시에 수행될 수 없으므로 임계영역이다
     - 판독기가 공유자원에서 데이터를 읽는 부분은 기록기가 쓰는 부분과 동시에 수행될 수 없으므로 임계영역이다

   - rcount = 0 (일반 변수)
     - 하나의 판독기가 임계영역을 수행 중일 때 다른 판독기도 임계영역을 수행할 수 있어야 하므로 일반 변수 rcount 를 두어 동시에 공유자원의 데이터를 읽는 판독기의 개수를 유지
     - rcount 가 1이상이 되면 공유자원을 읽는 판독기가 이미 있다는 것이므로 상호배제가 되지 않도록 P 연산을 생략한다
     - 임계영역 수행이 끝나고 rcount 를 1 줄였을 때 여전히 0보다 크다면 다른 판독기가 있다는 의미이므로 V 연산을 수행하지 않도록 한다
     - rcount 를 변화하고 확인하는 작업은 다른 판독기에 방해를 받으면 안되므로 임계영역으로 보고 mutex 를 사용하여 상호배제 처리 해준다
   - mutex = 1 (세마포어)
     - rcount 의 상호배제

   """ 기록기의 코드
   P(wrt)
   공유자원에 쓰기
   V(wrt)
   """

   """ 판독기의 코드
   P(mutex)
   rcount = rcount + 1
   if (rcount == 1) then P(wrt)
   V(mutex)
   공유자원 읽기
   P(mutex)
   rcount = rcount - 1
   if (rcount == 0) then V(wrt)
   V(mutex)
   """

2. 제2판독기-기록기 문제

   - rd = 1
   - wrt = 1
   - mutex1 = 1
   - mutex2 = 1
   - mutex3 = 1
   - rcount = 0
   - wcount = 0

   """ 기록기 코드
   P(mutex2)
   wcount = wcount + 1
   if (wcount == 1) then P(rd)
   V(mutex2)
   P(wrt)
   공유자원에 쓰기
   V(wrt)
   P(mutex2)
   wcount = wcount - 1
   if (wcount == 0) then V(rd)
   V(mutex2)
   """

   """ 판독기 코드
   P(mutex3)
   P(rd)
   P(mutex1)
   rcount = rcount + 1
   if (rcount == 1) then P(wrt)
   V(mutex1)
   V(rd)
   V(mutex3)
   공유자원 읽기
   P(mutex1)
   rcount = rcount - 1
   if (rcount == 0) then V(wrt)
   V(mutex1)
   """

# 프로세스 간 통신 (InterProcess Communication IPC)

병행 프로세스가 데이터를 서로 공유하는 방법

1. 공유 메모리 방법
   협력 프로세스가 동일한 변수(공유 자원)를 사용하여 데이터를 서로 공유하는 방법

   - 메모리에 직접 접근하여 대량의 데이터를 쓰거나 읽기에 적합
   - 빠른 속도
   - 상호배제나 동기화 등 문제를 응용 프로그래머가 책임

2. 메시지 전달 방법
   협력 프로세스가 메시지를 주고 받으면서 데이터를 서로 공유하는 방법

   - 커널모드에서 작동하는 send, receive 연산 사용
   - 시스템 호출을 사용하므로 소량의 데이터를 주고 받는데 적절
   - 운영체제가 상호배제나 동기화 문제에 책임

   * 통신 링크
     두 프로세스가 서로 메시지를 주고 받을 때 두 프로세스 사이에는 통신 링크가 존재

     - 링크의 방향성은 단방향/양방향 가능
     - 하나의 링크가 두 개의 프로세스만 연결하도록 하거나 여러 프로세스를 연결하도록 할 수 도 있음
     - 링크의 용량은 버퍼(큐)에 보관할 수 있는 메시지 수

   1. 직접통신
      두 프로세스가 직접 서로를 지정하여 메시지를 주고 받는 방법

   - 송신자는 send 연산에 수신자를 명시
   - 수신자는 receive 연산에 송신자를 명시
   - 직접통신은 서로를 지정한 두 프로세스 사이에 오직 하나의 통신 링크가 자동으로 설정됨
   - 양방향성
   - 송수신자가 각각 상대를 직접 명시하는 경우 대칭형 주소 지정, 수신자가 송신자를 미리 지정하지 않고 메시지를 받을 때 송신자 이름도 받는 경우 비대칭형 주소 지정

   2. 간접통신
      통신을 원하는 프로세스들 사이에 우편함을 두고 이를 통해 메시지를 주고 받는 방법

   - 송신자는 send 연산세 수신자 대신 우편함을 명시
   - 수신자는 receive 연산에 송신자 대신 우편함을 명시
   - 두 프로세스 사이 통신 링크는 같은 우편함을 이용하는 경우 설정된다
   - 송신자가 여럿이고 수신자가 하나라면 우편함이 수신자에 속한 경우로 단방향, 수신 프로세스가 종료되면 우편함도 사라짐
   - 수신자가 여럿인 경우 우편함이 운영체제에 소속되어 한순간에 하나의 수신자만 우편함에서 메시지를 받을 수 있도록 운영체제가 수신자를 관리 -> 송신자와 수신자의 역할이 바뀔수도 있으므로 통신 링크는 양방향

---

프로세스가 자원을 사용하는 절차는

1. 프로세스가 필요한 자원이 있으면 요구
2. 자원을 획득한 후 사용 (획득하지 못하면 대기)
3. 사용이 끝나면 획득했던 자원을 해제하고 반납

# 교착상태

여러 개의 프로세스가 서로 상대방의 작업이 끝나기만 기다리고 있기에 결과적으로 어느 쪽도 영원히 진행하지 못하는 상태
-> 관련된 모든 프로세스가 자원획득의 가능성 없이 무한히 대기 상태인 것

- 기아 상태: 관련된 프로세스의 일부가 자원획득의 가능성은 있으나 계속적으로 대기 상태인 것

## 교착상태의 필요조건

1. 상호배제 조건
   - 프로세스가 자원에 대한 배타적인 통제권을 요구하는 조건
   - 적어도 하나 이상의 자원은 여러 프로세스에 의해 동시에 사용될 수 없음
   - 필요로 하는 자원을 다른 프로세스가 점유하고 있으면 반드시 대기하게 된다
2. 점유대기 조건
   - 프로세스가 이미 한 자원을 할방받아 점유하고 있는 상황에서 다른 프로세스가 점유하고 있는 또 다른 자원을 요청하여 해제되기를 기다리는 상황
3. 비선점 조건
   - 프로세스에 할당된 자원은 프로세스가 사용을 마치고 스스로 반환하기 전 해제되지 않음을 의미
   - 할당된 자원은 타의에 의해서 해제 되지 않는다
4. 환형대기 조건
   - 프로세스의 자원 점유 및 점유된 자원의 요구 관계가 환형을 이루며 대기하는 상황

## 자원할당 그래프

교착상태를 명확하게 표현하기 위해 자원할당 그래프를 이용

- V: 정점의 집합
  - P: n 개의 프로세스 {p1, p2, ... pn} => 원
  - R: m개의 단위자원 {r1, r2, ... rm} => 사각형 (단위 자원의 개수를 숫자로 표시)
- E: 방향 있는 간선의 집합
  - Q: 프로세스 p가 자원 r을 요구한다(요구간선)
  - S: 자원 r가 프로세스 p에 할당된다(할당간선)

1. 가용한 단위자원이 존재하면 요구간선은 할당간선으로 바뀐다
2. 자원이 해제될 때 이 할당간선은 삭제된다

3. 교착상태의 환형대기 조건을 만족하는 것은 사이클이 존재한다
4. 교착상태의 점유대기 조건을 만족하는 것은 한 프로세스에 할당간선과 요구간선을 연결하는 것이다
5. 교착상태의 비선점 조건을 만족하는 것은 요구간선으로 표현되는 것이다
6. 교착상태의 상호배제 조건을 만족하는 것은 할당간선으로 표현되는 것이다

7. 자원할당 그래프의 기본 성질로 점유대기, 비선점, 상호배제 조건으로 만족되므로 사이클의 유무로 교착상태의 발생 가능성을 확인할 수 있다

## 교착상태 예방

1. 상호배제 제거

- 공유할 수 있는 자원은 상호배제가 필요하지 않으므로 교착상태를 유발하지 않으나 공유할 수 없는 자원은 상호배제를 따른다
- 그러므로 상호배제 조건을 제거하여 교착상태를 예방하는 것은 불가능

2. 점유대기 제거

- 자원을 점유했을 때 대기하지 않도록 하거나 대기할 때 자원을 점유하고 있지 않도록 한다
- 자원을 점유했을 때 대기하는 상황이 발생하지 않도록 필요한 모든 자원을 처음에 한꺼번에 요구하여 할당받으면 된다
- 자원을 미리 점유하게 되어 실제 자원이 필요한 시점까지 아무도 그 자원을 활용하지 못해 자원이용률이 낮아질 수 있으므로 기아상태에 빠질 수 있다
- 점유 도중 해제할 수 없는 자원에는 적용할 수 없다

3. 비선점 제거

- 자원의 특성에 따라 선점 가능하도록 만들 수 없다
- 차선책으로 자원을 점유한 프로세스가 다른 자원을 요구할 때 대기가 발생한다면 할당받았던 자원을 모두 해제하여 다른 프로세스가 비선점 조건으로 대기할 가능성을 줄인다

4. 환형대기 제거

- 모든 자원에 일련번호를 지정하고 프로세스 자원을 요구할 때 일련번호를 기준으로 항상 오름차순이 되도록 요구하는 것이 환형대기를 제거할 수 있다
- 프로세스가 자원을 요구할 때 그보다 일련번호가 큰 자원은 점유하고 있지 않도록 하는 방법 또한 환형대기를 제거할 수 있다
- 점유대기 중인 프로세스는 항상 점유하고 있는 자원의 일련번호보다 대기 중인 자원의 일련번호가 클수밖에 없다
- 프로세스마다 자원의 요구순서가 다를 수 있으므로 자원의 일련번호 설정에 어려움이 존재

## 교착상태 회피

프로세스의 자원 사용에 대한 사전 정보를 활용하여 교착상태가 발생하지 않는 상태에 머물도록 하는 방법
(사전 정보: 현재 할당된 자원, 가용상태의 자원, 프로세스의 최대 요구량)

### 안전상태

교착상태를 회피하면서 각 프로세스에 그들의 최대 요구량까지 자원을 할당할 수 있는 상태
즉, 안전순서열이 존재하는 경우로, 안전순서열은 순서있는 프로세스의 집합으로 각 프로세스는 추가로 요구할 수 있는 자원의 양이 현재 가용상태의 자원으로 충당되거나 현재 가용상태인 자원에 할당된 자원까지 포함하여 충당 가능한 경우를 의미
그러므로 안전순서열이 존재하는 경우 어떤 프로세스가 당장 자원을 할당받지 못하더라도 안전순서열에서 자신보다 순서가 빠른 프로세스들이 수행 후 자원을 해제할 때까지 대기하면 결국 자원을 얻을 수 있는 것이다.

### 불안전상태

안전순서열이 존재하지 않는 경우, 다만 불안전상태라고 무조건 교착상태인 것은 아니다.

### 변형된 자원할당 그래프

각 자원의 단위자원이 하나밖에 없을 경우, 단위자원의 개수가 사라지고 선언간선이 추가된 것

- 선언간선은 프로세스가 언제일지 모르지만 앞으로 분명이 자원을 요구하게 될 것임을 나타냄, 요구간선과 동일하게 프로세스에서 자원으로 방향성을 지니므로 점선으로 표시

### 은행원 알고리즘

자원의 단위자원이 여러 개인 경우 은행원 알고리즘으로 교착상태를 회피할 수 있다. 자원을 요구받으면 그 자원을 할당해주고 난 후의 상태를 여러 데이터를 이용하여 계산해서 안전상태인지 확인한 후 안전상태가 보장되는 경우에만 자원을 할당한다.

- MAX : 프로세스의 각 자원에 대한 단위자원의 최대 요구량
- ALLOC: 프로세스의 현재 할당된 단위자원 개수
- NEED: 프로세스의 각 자원에 대한 추가 단위자원 요구량
  - MAX = ALLOC + NEED
- AVAL: 현재 가용한 각 자원의 단위자원의 수
- REQ: 프로세스가 자원을 k개 요구하는 상황
  - REQ <= NEED 이고 REQ <= AVAL 이면 오류도 없고 가용한 자원도 있는 경우이므로 할당해도 안전상태가 유지되는지 확인
  - REQ > NEED 거나 REQ > AVAL 이면 오류로 판단

""" 은행원 알고리즘
void bank(REQ) {
if (!(REQ) <= NEED) 오류;
if (!(REQ) <= AVAL) 프로세스 대기;

      ALLOC = ALLOC + REQ;
      NEED = NEED - REQ;
      AVAL = AVAL - REQ;

      status = safe(상태 데이터);
      if (state == true)
         REQ대로 할당; // 안전상태
      else
         프로세스 대기;
         상태 데이터 복구; // 불안전상태

}

boolean safe(상태 데이터) {
WORK = VAVL;
for (i = 1; i <= n; i++) FINISH[i] = false;
for (l = i; l <= n; l++) {
for (i = 1; i <= n; i++) {
if (FINISH[i] == false && NEED <= WORK) {
WORK = WORK + ALLOC;
FINISH[i] = true;
break;
}
}
if (i > n) break;
}
if (모든 i에 대해 FINISH[i] == true) return true; // 안전상태
else return false; // 불안전상태
}
"""

## 교착상태 탐지

교착상태를 탐지하면 교착상태를 해결하는 방법으로 쇼사니와 코프만 알고리즘을 수행한다.

### Shoshni and Coffman 알고리즘

은행원 알고리즘을 안전 알고리즘과 유사하나 현재 상태의 모든 자원 요구량을 고려하여 교착상태 여부를 확인

- 교착상태와 무관한 프로세스는 제외하기 위해 점유대기 조건에 해당하지 않는 ALLOC가 0인 프로세스는 초기화에서 FINISH를 true로 둔다
- 가용 가능한 자원량이 현재 요구량을 충족시켜 줄 수 있다면 역시 FINISH를 true 로 둔다
- 즉 FINISH가 false 인 프로세스가 존재한다면 교착상태로 판단한다

""" 교착상태 탐지 알고리즘
boolean detect(상태 데이터) {
WORK = AVAL;
for (i = 1; i <= n; i++) {
if (ALLOC != 0) FINISH[i] = false;
else FINISH[i] = true;
}

      for ( l = 1; l <= n; l++) {
         for (i = 1; i <= n; i++) {
            if (FINISH[i] == false && REQ <= WORK) {
               WORK = WORK + ALLOC;
               FINISH[i] = true;
               break;
            }
         }
         if (i > n) break;
      }
      if (FINISH[i] == false) return true; // 교착상태
      else return false; // 교착상태가 아님

}
"""

- 탐지 알고리즘은 O(mn^2) 시간에 수행되므로 자원 요구가 생길 때마다 수행하는 것은 비용이 크기 때문에 아래와 같은 때 시행한다
  - 즉시 받아들일 수 없는 자원 요구가 있을 때
  - 정해진 시간간격
  - CPU 효율이 일정 수준 이하로 떨어질 때

## 복구

- 오퍼레이터에게 교착상태가 발생했음을 알려 직접 수작업으로 처리
- 운영체제가 자동으로 교착상태로부터 복구
- 복구를 위한 프로세스를 선택할 때 복구 횟수를 고려하여 기아상태에 빠지지 않도록 해야 한다

### 교착상태 복구방법

1. 교착상태 프로세스를 종료
2. 교착상태 프로세스가 할당받은 자원을 해제하는 방법
   위와 같은 방법으로 환형대기를 없앨 수 있다

### 프로세스 종료

1. 모든 교착상태 프로세스 종료
   진행했던 내용에 대한 복원 비용이 큼
   프로세스의 우선순위, 진척도, 사용된 자원의 유형, 양 등 여러 요소 고려
2. 사이클이 제거될 때까지 프로세스를 하나씩 종료
   제거한 프로세스에 할당된 자원을 단계적으로 선점하여 이 자원을 다른 프로세스들에 할당
   프로세스의 진척도, 자원의 수, 복귀 시점 고려

# 프로세스와 메모리

- 프로세스가 동작하기 위해 CPU, 메모리, I/O장치, 파일 등의 자원을 할당받아야 하는데, 그중에서도 CPU와 메모리는 필수 요소이다.
- 프로세스가 실행 상태에서 동작은 프로그램 카운터(PC)를 참조하여 수행될 명령을 읽어와서 CPU의 해당 명령을 수행하는데 프로그램 카운터가 가리키는 주소라는 것이 결국 메모리상의 특정 위치가 된다.

- 새로운 프로세스를 언제 메모리에 둘 것인지 고려
- 다음에 실행될 프로세스를 메모리 내의 어느 곳에 둘건지 고려
- 메모리가 꽉 찬 상태에서 새로운 프로세스를 메모리에 적재해야 할 때 어떤 프로세스를 제거할 것인지 고려
- 고정 분할/동적 분할 고려
- 프로세스의 적재영역이 고정적/유동적인지 고려
- 메모리의 낭비를 줄이기 위해 많은 양의 프로세스를 메모리에 둘 것인지, 필요한 부분만 메모리 내에 둘 것인지 고려
- 자주 사용되지 않는 프로세스, 최근에 쓰이지 않는 프로세스가 무엇인지 등의 메모리 관리하기 위해 고려

## 기억장치의 계층구조

< 접근속도가 빠름/비트당 기억장치 비용이 높음 대용량 >
CPU(레지스터) <-> 캐시 메모리 <-> 메모리 <-> 보조기억장치

- 자주 실행되는 프로세스는 캐시에 두고 실행속도를 향상시킨다

## 환경

### 단일 프로그래밍 환경

오직 하나의 프로세스만 메모리를 전용으로 사용했기에 프로세스는 하나의 연속된 블록으로 메모리에 할당되는 연속 메모리 할당 방식을 이용

- 메모리 용량을 초과하는 프로세스는 실행될 수 없다
- 지속적으로 사용되지 않는 프로세스도 메모리에 적재되어 있어야 하므로 메모리 낭비가 심함
- 한 명의 사용자가 메모리를 전용하기에 대기하게 되어 자원의 낭비가 심함

### 다중 프로그래밍 환경

여러 개의 프로세스가 메모리에 동시에 적재되는 것

- 여러 메모리에 CPU 연산과 입출력을 나누고 동시에 실행되게 함으로써 시스템 처리량을 증가시킬 수 있다

## 메모리 분할

여러 프로세스를 메모리에 적재하기 위해 고안된 방법으로 하나의 분할에 하나의 프로세스가 적재되는 방식

### 고정 분할

메모리를 여러 개의 고정된 크기의 영역으로 분할하는 방식

- 내부 단편화: 프로세스의 크기가 적재된 분할영역의 크기보다 작아서 분할영역 내에 남게 되는 메모리는 결국 낭비

1. 각 분할 영역마다 큐를 두고 큐에 들어온 프로세스는 해당 분할 영역에만 적재되도록 하는 것
   - 프로그램 컴파일 시 프로그램 내의 주소를 절대주소로 번역하여 해당되는 특정 분할영역에만 적재되어야 하는 방식
   - 구현이 용이하나 큐가 빈 분할이 있어도 다른 큐의 프로세스는 적재할 수 없어서 효율성이 낮다
2. 메모리 전체에 하나의 큐만 두고 모든 프로세스를 하나의 작업 큐에 넣어서 어느 분할에서든지 실행 가능하게 하는 것
   - 컴파일 시 프로그램 내 주소를 상대 주소로 번역하여 어디든 적재가 가능한 방식
   - 기억장치의 낭비를 줄이지만 재배치 가능 번역기와 로더는 절대번역기보다 더 복잡하다

### 동적 분할

각 프로세스에 필요한 만큼의 메모리만 할당하는 방식

- 외부 단편화: 메모리 할당과 반환이 계속 반복됨에 따라 작은 크기의 공백이 메모리 공간에 흩어져 생기는 것
  - 통합: 인접된 공백을 더 큰 하나의 공백으로 만드는 과정
  - 집약: 메모리 내의 모든 공백을 하나로 모으는 작업
- 내부 단편화 X

## 메모리 보호

연속 메모리 할당 방식에서는 프로세스가 사용할 수 있는 주소 범위를 하한-상한 레지스터 쌍 또는 하한-크기 레지스터 쌍으로 제한하여 다른 할당영역을 침범하지 않게 한다
이 때 프로세스가 제한을 넘어 운영체제를 호출하면 시스템 호출을 통해서만 가능하다

## 메모리 배치

동적 분할 다중 프로그래밍에서 새로 반입된 프로그램이나 데이터를 메모리의 어느 위치에 배치할 것인가 결정하는 것

1. 최초 적합
   빈 공간 리스트를 메모리의 주소순으로 유지하여 프로세스가 적재될 수 있는 빈 공간 중에서 가장 먼저 발견되는 곳에 할당

2. 후속 적합
   이전 탐색에 끝난 그 다음부터 시작하여 사용 가능한 빈 공간 중에서 가장 먼저 발견되는 곳에 할당

3. 최적 적합
   큰 빈 공간을 최대한 많이 남겨 놓기 위한 방법으로 필요한 공간을 빈 공간 중에서 가장 작은 곳을 선택하여 할당

4. 최악 적합
   필요한 공간을 제공할 수 있는 빈 공간 중 가장 큰 곳을 선택하여 할당
   이는 작은 공간이 남아 사용하지 못하는 공간이 발생하는 것을 최소화하기 위한 방법

# 가상 메모리

컴퓨터 시스템의 메모리 크기보다 더 큰 기억 공간이 필요한 프로세스를 실행할 수 있게 하는 방법

- 실행 중인 프로세스에 의해 참조되는 주소를 메모리에서 사용하는 주소와 분리하는 것

* 가상 주소: 실행 프로세스가 참조하는 주소
* 실주소/물리적 주소: 실제 메모리에서 사용하는 주소

* 가상주소 공간: V, 실행 프로세스가 참조하는 가상주소의 범위
* 실주소 공간: R, 사용 가능한 실주소의 범위
  프로세스는 가상주소만 참조하지만 실제로 메모리에서 실행되어야 하므로 프로세스가 실행되면 가상주소는 실주소로 변환되어야 하므로 운영체제에서 사상(mapping)이 된다

## 동적 주소변환(DAT)

프로세스가 실행되는 동안 가상주소를 실주소로 바꾸는 절차
프로세스의 가장주소 공간에서 연속적인 주소가 실주소 공간에서도 연속적일 필요는 없다는 인위적 연속성을 가지고 있다

## 블록 단위 주소변환

동적 주소변환(DAT) 방식은 가상 메모리에서 위치가 현재 메모리의 어디에 위치하는지 나타내는 주소변환 사상표를 유지해야 한다

주소변환이 가상주소 내 각 항목별로 바이트나 워드 단위로 이루어지다면 변환에 필요한 정보량이 너무 많아져서 프로세스가 요구하는 메모리 공간보다 사상표가 더 큰 메모리 공간이 필요하게 되므로 가상 메모리를 효율적으로 구현하려면 사상정보의 양을 줄여야 하므로 항목대신 블록 단위로 주소변환이 이루어지는 방식을 블록 단위 주소변환이라 한다

### 블록 사상 시스템

각 블록이 메모리의 어디에 위치하는지 관리
가상주소 = (블록번호, 변위) => v = (b, d)

1. 블록: 특정 항목을 참조하기 위해 그 항목이 들어있는 곳
2. 변위: 블록의 시작 부분으로부터 항목까지 위치

- 블록 크기가 커질수록 사상정보 저장에 필요한 메모리의 양은 작아지는 대신 블록을 보조기억장치에서 메모리로 이동시키는데 필요한 전송시간이 늘어나고 한 블록이 차지하는 메모리 공간이 커져서 메모리를 공유할 수 있는 프로세스의 수가 줄어든다

### 페이징 기법

페이지: 가상 메모리의 크기가 동일한 블록
가상주소 = (페이지번호, 변위) => v = (p, d)
ex) 3번 페이지 안, 8byte 만큼 떨어져 있다면 v=(3, 8)이 되어 페이지의 크기가 1024byte 일 때 1024\*3 + 8 = 3080 이 된다

- 프로세스 사이 메모리 보호는 페이지 단위로 이뤄짐
- 메모리도 동일 크기의 페이지 프레임으로 나뉘어 사용
- 외부 단편화가 아닌 페이지 내부에 내부 단편화가 발생

#### 페이지 프레임

프로세스가 실행되기 위해 특정 페이지를 참조하려면 해당 페이지는 메모리상에 위치해야 한다. 그러므로 메모리 영역도 가상 메모리와 동일하게 고정된 크기의 블록으로 나누어 두고 각 블록을 페이지 프레임이라고 한다. 페이지 프레임 아무 곳에 페이지가 적재된다.

#### 페이지 사상표

페이지가 메모리에 적재된 후 바로 찾을 수 있도록 프로세스가 사용하는 가상주소를 실주소로 동적 변환 할 수 있어야 한다.
이때 페이지 사상표를 이용하여 가상주소의 페이지 번호에 대한 실주소의 페이지 프레임 번호가 저장되어 있으므로 실주소로 동적 변환한다.

1. 직접사상: 페이지 사상표를 직접 이용하여 동적 주소변환을 하는 것
2. 연관사상: 페이지 변환 정보를 연관 메모리에 저장한 연관사상표를 이용하여 동적 주소변환을 하는 방식
   - 연관 메모리: 저장된 값을 이용하여 데이터를 액세스하는 고속 메모리 장치
     실제로는 직접사상과 연관사상을 같이 사용하여 연관사상표에는 가장 최근 참조된 페이지 항목만 보관하고 나머지는 페이지 사상표에 수록하여 연관사상표에 없을 때만 직접사상을 이용하도록 구현한 것

### 세그먼테이션 기법

세그먼트: 모듈화에 따른 논리적 의미에 부합하는 다양한 크기의 블록
가상주소 = (세그먼트번호, 변위) => v = (s, d)
세그먼트를 메모리에 적재하려면 수용할 수 있을 만큼 충분히 큰 메모리의 사용 가능한 영역에 놓는다. (최초적합/최적적합과 동일)

#### 세그먼트 사상표

해당 세그먼트가 현재 메모리에 존재하는지 여부를 나타내는 비트값과 보조기억장치에서의 위치정보, 세그먼트의 길이(세그먼트 오버플로를 확인) 등이 저장되어 있다.

### 페이징/세그먼테이션 혼용 기법

세그먼테이션 기법의 논리적 장점과 페이징 기법의 메모리 관리 측면의 장점을 활용하기 위한 기법
각 세그먼트를 다시 페이지 단위로 분할하고 메모리도 페이지 프레임으로 분할하여 하나의 페이지만 페이지 프레임에 적재하는 방식
가상주소 = (세그먼트번호, 페이지번호, 변위) => v=(s, p, d)

1. 가장 최근에 참조된 페이지는 연관사상표에 있으므로 우선 연관메모리에서 (s, p)를 찾기 위한 탐색이 이루어진다
2. p에 의한 페이지 프레임이 d와 합하여 v=(s, p, d)에 대응하는 실주소를 생성한다
3. 연관사상표에 없는 경우 직접사상 변환은 메모리의 세그먼트 사상표의 시작주소 b가 세그먼트 번호 s와 더해져 세그먼트 사상표의 항목주소 b+s를 생성한다

## 메모리 호출 기법

어느 시점에 페이지/세그먼트를 메모리에 적재할지 결정하는 기법

### 요구 페이지 호출기법

한 프로세스의 페이지 요구가 있을 때 요구 페이지를 메모리에 적재하는 방법
각 페이지는 실행 중인 프로세스에 의해 명백히 참조될 때에만 보조기억장치에서 메모리로 옮겨진다

- 오버헤드 최소화
- 페이지 부재 발생
- 옮겨진 페이지는 모두 프로세스에 의해 실제로 참조된 것

### 예상 페이지 호출기법

현 시점에서 액세스되고 있지 않지만 곧 사용될 것으로 예상되는 페이지를 미리 메모리에 옮겨 놓는 방법

- 예상이 옳았다면 실제로 필요한 시점이 되었을 때 프로세스의 실행이 단절되지 않아 실행시간이 감소
- 예상이 잘못된 경우에는 예상 적재에 따른 시간과 메모리 낭비 발생

## 페이지 교체 알고리즘

페이징 기법에서는 모든 페이지 프레임이 사용되고 있는 것이 일반적이므로 메모리에 새로 적재되어야 할 페이지를 위해 적절한 교체 대상 페이지 프레임을 선택하여 그 내용을 보조기억장치에 보관된 후 새로운 페이지를 적재해야 한다

- 최적화 원칙: 페이지 프레임에 있는 페이지 중 이후로 가장 오랫동안 사용되지 않을 페이지를 교체 대상으로 선택 => 미래를 예측할 수 없으므로 실제 구현은 불가하나 시간 및 공간의 오버헤드가 적은 방법을 선택

### 교체가 일어나지 않아야 하는 페이지 종류

1. 페이징을 위한 커널 코드 영역
2. 커널에 속하지 못한 보조기억장치 드라이버 영역
3. 시간을 맞춰 동작해야 하는 코드 영역
4. DMA(Direct Memory Access) 등에 의해 입출력장치로부터 직접 데이터가 교환되어야 하는 데이터 버퍼 영역

### FIFO 페이지 교체

First In First Out => 큐 이용 (페이지 추가 시 trail에, 페이지 교체 대상은 head)
메모리 내 가장 오래 있었던 페이지를 교체 대상으로 선택하여 교체
다만 실제로 메모리에 가장 오랫동안 있었던 페이지는 앞으로도 계속 사용될 가능성이 높기에 가장 많이 쓰는 페이지를 교체시킬 가능성이 있다

- Belady 이상현상: 프로세스에 더 많은 수의 페이지를 할당할 경우 오히려 페이지 부재가 더 많이 발생할 수 있다는 것

### LRU 페이지 교체

Least Recently Used
메모리 내 가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택으로 교체

- 국부성 휴리스틱: 최근의 상황이 가까운 미래에 대한 좋은 척도
- 국부성(locality): 프로세스는 기억장치 내의 정보를 균일하게 액세스하는 것이 아니라 어느 한순간에 특정 부분을 집중적으로 참조

1. 시간 국부성: 처음 참조된 기억장소가 가까운 미래에도 계속 참조될 가능성이 높다
2. 공간 국부성: 하나의 기억장소가 참조되면 그 근처의 기억장소가 계속 참조되는 경향이 있다

- Belady의 이상현상이 발생하지 않고 최적화 원칙에 맞는 선택이 가능하지만 경험적 판단이 맞지 않는 상황도 존재할 수 있다
- 리스트, 참조시간을 위한 테이블 등 막대한 오버헤드를 초래

#### LRU 페이지 교체 알고리즘 구현 방식

1. 참조시간 이용
   각 페이지 참조될 때마다 그때의 시간을 기록하여 교체가 필요한 경우 참조시간이 가장 오래된 페이지가 교체 대상으로 선택된다

2. 리스트 이용
   리스트를 이용하여 페이지를 액세스하면 해당 페이지 번호를 리스트의 선두에 옮겨 교체가 필요한 경우 리스트의 끝에 있는 페이지가 교체 대상으로 선택된다

### LFU 페이지 교체

Least Frequency Used
페이지가 얼마나 많이 사용되었는지에 착안한 방법
메모리 내 참조된 횟수가 가장 적은 페이지를 교체 대상으로 선택하여 교체한다

- 가장 드물게 이용되는 페이지가 가장 최근에 메모리로 옮겨진 페이지일 가능성이 있다
- 초기에 많이 사용된 후 더이상 사용되지 않는 페이지는 교체 대상에서 제외됨으로써 불필요하게 메모리를 점유할 가능성이 있다
- 참조 횟수를 기록하고 가장 적은 참조 횟수를 찾는 것은 오버헤드가 크다

### 2차 기회 페이지 교체

참조 비트가 0이면서 메모리 내 가장 오래 있었던 페이지를 교체 대상으로 선택하여 교체
이때 자주 참조되는 페이지에 교체되지 않고 메모리에 남아있게 해줄 수 있는 2차 기회를 참조 비트를 준다

- 참조 비트: 페이지 프레임에 있는 페이지마다 부여된 값 (처음 적재될 때 0, 이후로 해당 페이지가 참조되면 1)

* 큐가 꽉 찬 경우에만 삭제가 발생하기 때문에 하나의 포인터만으로 구현 가능
* 포인터는 항상 마지막에 추가된 페이지의 다음 위치를 가리킨다 (페이지 프레임이 꽉 차지 않았다면 포인터는 빈칸을 가리킴)

### 클럭 페이지 교체

2차 기회 페이지 교체에서 큐를 변형된 원형 큐로 관리하는 경우
원형 큐가 시곗바늘이 돌아가는 것처럼 관리되므로 구현 시 원형 큐의 형태로 앞 뒤의 위치를 head, tail 포인터로 관리

## 프로세스별 페이지 집합 관리

각 프로세스가 사용할 수 있는 페이지 프레임의 개수를 프로세스별 페이지 집합이라 하며, 이는 컴퓨터 시스템의 성능에 영향을 준다

- 집합 크기가 작을수록 메모리에 적재할 수 있는 프로세스의 수는 많아져서 시스템 처리량이 증대될 수 있지만 페이지 부재는 자주 발생하게 된다

### 페이지 집합을 관리하는 알고리즘

1. 워킹 세트 알고리즘
   페이지 부재비율을 감소시키기 위해 데닝이 제안한 모델

- 워킹 세트는 한 프로세스가 최근에 참조한 페이지의 집합으로 W(t, d)는 시각 t에 t를 포함한 직전 d시간 동안 참조한 페이지의 집합
  - d는 워킹 세트의 window 크기
  - t-d+1 부터 t까지 참조한 페이지의 집합
  - 윈도 크기가 고정되어 있어도 워킹 세트의 크기는 달라질 수 있음
- 프로세스가 효율적으로 수행되기 위해 프로세스의 워킹 세트가 메모리 내 유지되어야 함, 즉 프로세스마다 워킹 세트의 크기에 맞게 페이지 프레임의 개수를 조절함
- 워킹 세트가 메모리 내 유지되지 않으면 보조기억장치로부터 계속해서 페이지를 요구하게 되므로 쓰레싱이 유발됨

  - 쓰레싱: 페이지 부재가 비정상적으로 많이 발생하여 프로세스 처리보다 페이지 교체처리에 많은 시간을 소비하여 시스템 처리량이 급격히 저하되는 현상

- 워킹 세트를 정확히 알아서 업데이트 하는 것이 현실적으로 어려움
- 윈도 크기 d의 최적값을 알기 어려움

2. PFF 알고리즘
   Page Fault Frequency
   페이지 부재 빈도(PFF)를 이용하여 프로세스별 페이지 집합의 크기를 변화시키는 기법

- 페이지 부재 빈도: 얼마나 자주 페이지 부재로 교체가 발생하는지 나타내는 척도 - 페이지 부재가 발생하면 직전 페이지 부재 이후로 경과된 시간의 역수

* 페이지 부재 빈도가 상한보다 높으면 페이지 프레임의 개수를 1 증가
* 페이지 부재 빈도가 하한보다 낮으면 참조되지 않았던 페이지를 모두 제거하고 페이지 프레임 개수를 1 감소

* 워킹 세트 알고리즘처럼 자주 바뀌지 않음
* 페이지 부재가 발생하면 그 때 페이지 부재 빈도의 상한/하한을 벗어나는 경우에만 변경됨

# 장치 관리

## 장치

컴퓨터 시스템에는 CPU, 메모리, 키보드, 마우스, 네트워크 카드, 디스크 드라이브 등의 장치가 존재
프로세스 관점에서 CPU와 메모리는 프로세스를 실행시키기 위한 필수 요소지만 나머지 장치들을 프로세스 실행 시 데이터 입력이나 출력에 사용되는 입출력장치로 분류된다

## 입출력장치

장치 간 기능적 특성뿐 아니라 장치관리자에 의해 관리되는 방법에 따라 3가지로 분류

1. 전용장치
   한번에 하나의 프로세스만 할당
   즉 활성화될 때 전체 시간이 할당된다 => 하나의 사용자에게만 할당되므로 대기시간이 길어진다
   ex. 테이프 드라이브, 프린터, 플로터

2. 공용장치
   여러 프로세스에 할당 => 스케줄링 기법 필요
   ex. 디스크 팩 같은 직접접근 저장장치

3. 가상장치
   공유 가능한 장치를 이용하여 전용장치를 공용장치처럼 보이게 하여 여러 프로세스에 할당하는 것
   ex. 플로터에 디스크를 이용한 스풀링을 적용하여 공유 가능한 가상의 플로터로 변화
   - 스풀링: 입출력 프로세스와 저속 입출력장치 사이의 데이터 전송을 자기 디스크와 같은 고속장치를 통하도록 하는 것

## 장치의 구성

### 논리적 구성

1. 장치제어기
   - 장치를 직접적으로 다루는 장치
   - 장치 안에 포함되어 있거나 독립적으로 존재
   - 장치에서 발생하는 각종 데이터를 전자신호로 변환하여 운영체제로 보내고 운영체제가 요청하는 명령을 받아 장치를 구동
2. 장치 드라이버
   - 응용 프로그램이 요청한 입출력 요청을 해당 장치에 맞도록 변환
   - 장치 종류나 제조사에 따라 장치제어기가 이해하는 명령이 다를 수 있기 때문
3. 장치

### 물리적 구성

- CPU, 메모리, 그외 장치들이 버스로 연결되어 CPU는 장치제어기에 명령을 보낼 수 있다
- CPU와 장치제어기 사이 메모리 사상 입출력(memory mapped I/O) 방식으로 명령을 보낼 수 있다
  - 메모리 사상 입출력: 메모리의 특정 영역을 장치제어기의 레지스터와 대응시켜 CPU는 메모리에서 읽고 쓰는 일반적인 명령을 수행하는 것

## 입출력 처리 유형

### 프로그램 방법

- CPU만 이용하여 입출력을 처리하는 것
- 폴링: CPU가 입출력장치의 상태를 지속적으로 확인하여 CPU가 원하는 상태가 될 때까지 기다리는 것
- CPU의 낭비가 심함

### 인터럽트 방법

- 인터럽트: 어떤 장치가 다른 장치의 작업을 잠시 중단시키고 자신의 상태를 알리는 기능
- 장치가 특정 상태가 되었을 때 CPU에게 자신의 상태를 알려줌

1. 입출력장치가 가용상태가 되었다고 인터럽트 제어기에 신호를 보냄
2. 인터럽트 제어기는 CPU에 인터럽트 신호를 보냄
3. CPU는 현재 싱행 중이던 명령을 마치고 인터럽트에 응답
4. 인터럽트 제어기는 응답을 받으면 이벤트 대상에 대한 정보를 CPU에 보냄
5. CPU는 현재 상태를 보관하고 필요한 입출력 처리를 한 후 원래 프로세스 실행상태로 복귀

### DMA 방법

Direct Memory Access

- DMA 제어기를 이용하여 CPU를 통하지 않고 메모리에 직접 접근하여 데이터를 전송하는 방법

1. CPU는 입출력에 필요한 정보를 DMA 제어기에 보냄
2. DMA 제어기는 장치제어기에 소스와 목적지로 데이터를 보내도록 요청
3. 원하는 양의 입출력이 끝나면 DMA 제어기는 입터럽트 제어기에 신호를 보냄
4. 인터럽트로 인해 CPU에 입출력 작업이 끝났음을 알림

- 한번에 입출력량이 많은 경우 인터럽트 발생 횟수를 한번으로 줄여줘서 CPU 효율을 증대
- CPU, DMA 제어기 모두 메모리에 액세스하므로 동시에 액세스를 시도하면 충돌이 발생 => 사이클 스틸링
  - 사이클 스틸링: CPU 보다 DMA 제어기에 우선권을 주는 것

## 입출력 관리

### 버퍼링

- 버퍼: 입출력 데이터 등 정보를 전송할 때 일시적인 데이터 저장장소로 사용되는 메모리 일부
- CPU 데이터 처리속도와 데이터 전송속도의 차이를 해결

- 단일 버퍼링: 입출력장치가 데이터를 버퍼에 저장하면 CPU는 그 데이터를 처리하고 다시 입력장치가 다음 데이터를 저장하면 CPU가 또 처리하는 방식, 즉 저장과 처리를 동시에 할 수 없음
- 이중 버퍼링: 데이터의 저장과 처리가 동시에 일어날 수 있음
- 순환 버퍼링

### 스풀링

입출력 프로세스와 저속 입출력장치 사이의 데이터 전송을 자기 디스크와 같은 고속장치를 통하도록 하는 것
스풀링을 통하면 고속의 공용장치인 디스크라는 스풀에 데이터를 저장하는 것으로 작업이 끝나므로 프로세스는 바로 다음 명령을 실행할 수 있는 것이다
독립적으로 사용해야하 하는 장치를 여러 프로세스가 동시에 사용할 수 있는 것처럼 보이게 하는 가상장치로 변화시켜준다

## 저장장치

### 순차접근 저장장치

데이터를 순차적으로 기록하고 판독하는 저장장치
대량의 데이터 백업용으로 주로 사용
ex. 테이프 장치: 릴에 테이프가 감긴 형태로 특정 데이터를 찾으려면 우선 원하는 위치가 나올 때까지 테이프를 풀어야 하므로 초기 접근시간이 오래 걸림

### 직접접근 저장장치 (임의접근 저장장치)

지정한 위치를 직접 찾아 데이터를 읽거나 쓸 수 있는 장치
ex. 자기 디스크, 광디스크, SSD

1.  자기 디스크
    자성을 띈 디스크의 표면에 데이터를 쓰거나 읽을 수 있는 저장장치
    - 플래터가 간격을 두고 쌓여 있는 형태로 플러터마다 기록하고 판독할 수 있는 헤드가 암에 연결되어 있음
    - 데이터가 저장되는 각 플래터의 표면은 플래터의 중심축을 기준으로 동심원 형태인 트랙으로 나뉨
    - 트랙은 일정한 용량을 저장할 수 있는 호 형태의 섹터로 나뉨
    - 플래터의 중심축으로부터 같은 거리에 있는 트랙들을 모아 하나의 실린더를 구성
      자기 디스크에서 데이터를 읽거나 쓰려면 암을 움직여 헤드를 원하는 트랙에 위치시킨 후 플래터를 회전시켜 원하는 섹터를 헤드에 위치
2.  광디스크
    자성 대신 빛을 이용하여 디스크 표면에 레이저를 쏘아 반사되는 빛의 차이를 이용하도록 데이터를 다루는 저장장치
    - 나선형인 하나의 트랙으로 구성
      ex. CD-ROM, DVD-ROM, Bluray...
3.  SSD(Solid State Disk)
    플래시 메모리처럼 읽고 쓰기가 가능하면서 전력 공급이 없어도 데이터가 지워지지 않는 저장장치
    - 속도가 빠름
    - 물리적인 장치가 없어 전력소모가 적음
    - 용량 대비 가격이 비싸고 수명이 짧음

## 디스크 스케줄링 알고리즘

디스크 접근 요구(읽고 쓰기)를 효율적으로 처리하는 순서를 결정하는 작업
다중 프로그래밍 환경에서는 많은 프로세스가 디스크 접근 요구를 발생시킬 수 있어 이러한 요구들을 디스크 큐에 두고 관리

디스크는 헤드의 이동, 디스크의 회전과 같은 기계적인 움직임에 의해 직접접근을 하기므로 디스크 스케줄러는 대기하고 있는 요구들 간의 위치적 관계를 조사하고 나서 최소한의 기계적 동작에 의해 접근 요구를 처리할 수 있도록 디스크 큐를 재배열한다

- 디스크 접근 요구를 처리하는데 필요한 시간의 요소
  1.  탐구 시간 (seek time)
      기계적인 동작에 의해 암을 움직여 헤드를 원하는 트랙에 위치시키는데 걸리는 시간
  2.  회전지연시간 (rotational latency time) = 탐색시간 (search time)
      헤드가 위치한 트랙에서 요구된 자료가 헤드 밑에 이를 때까지 디스크가 회전하는데 걸리는 시간
  3.  전송시간 (transfer time)
      현재의 트랙의 헤드 위치에서 자료를 읽거나 쓰는데 걸리는 시간
      스케줄링과 무관하게 항상 동일하게 필요한 부분
- 디스크에 데이터를 읽거나 쓰는데 걸리는 전체 시간은 탐구시간+회전지연시간+전송시간
- 탐구시간의 최적화와 회전지연시간의 최적화로 탐구시간이 더 중요하므로 탐구시간을 최소화하는 스케줄링 알고리즘을 결정

### FCFS

First Come First Served
먼저 도착한 접근 요구가 먼저 서비스를 받는 방법

- 디스크 큐에 일단 접근 요구가 도착하면 실행 예정순서가 고정된다는 점에서 공평
- 디스크 부하가 낮을 때는 사용할 만하나 부하가 높으면 응답시간이 길어짐

### SSTF

Shortest Seek Time First
탐구시간이 가장 짧은 접근 요구를 먼저 처리하는 방법

- FCFS 보다 처리량이 많고 평균응답시간은 비교적 짧음
- 현재 헤드 위치에 가까운 접근 요구가 들어오게 되면 상대적으로 먼 쪽인 양 끝 트랙은 기아상태에 빠질 수 있음
- 처리량이 중요한 일괄처리 운영체제에 적합
- 응답시간의 편차가 크기에 시분할 시스템에선 사용되지 않음

### SCAN

양 끝 트랙 사이를 왕복하며 진행방향의 가장 가까운 접근 요구를 먼저 처리하는 방법

- SSTF 스케줄링의 응답시간 편차를 어느 정도 해소함
- 다만 한 방향의 마지막 트랙까지 갔다가 방향을 바꾸므로 헤드 바로 뒤에 도착한 접근 요구를 되돌아올 때까지 기다려야 하는 불공평함
- 트랙은 헤드의 진행방향마다 지나치므로 헤드가 한 번 왕복할 때 두 번의 서비스 기회가 있지만 트랙의 양 끝은 헤드가 한 번 왕복할 때 한 번의 서비스 기회만 있다

### C-SCAN

한쪽 방향으로만 진행방향의 가장 가까운 접근 요구를 처리

- 양 끝 트랙에 대한 접근 요구의 차별을 제거하고 응답시간의 편차도 매우 작음

### LOOK

SCAN 스케줄링의 변형으로 진행방향의 앞 쪽에 더 이상 접근요구가 없으면 바로 방향을 바꾸는 방법

### C-LOOK

C-SCAN 스케줄링의 변형으로 반대편 트랙 끝까지 이동하지 않고 가장 먼 접근 요구의 트랙까지만 이동함

### SLTF

Shortest Latency Time First
회전지연시간 최적화를 위한 알고리즘으로 동일 실린더의 여러 섹터에 대한 접근 요구에 대해 회전지연시간이 가장 짧은 것을 먼저 처리하는 방법

- 높은 부하상태에서 유용

# 파일 관리

## 파일 관리자

운영체제의 주요 구성요소

- 액세스 방식: 파일에 저장되어 있는 데이터에 접근하는 방식을 정함
- 파일 관리: 파일을 저장, 참조, 공유할 수 있도록 하며 안전하게 보호될 수 있도록 함
- 보조기억장치 관리: 보조기억장치에 파일을 저장하는데 필요한 공간을 할당
- 파일 무결성 유지: 파일 정보가 소실되지 않도록 보장

특히 파일 관리 시스템은 보조기억장치 중 디스크 장치를 관리하는 일과 관련하여 2단계 계층구조 파일 시스템 구조를 가짐

1. 루트: 디스크의 루트 디렉터리가 시작되는 위치.
   - 여러 개의 사용자 디렉터리를 가짐
2. 사용자 디렉터리: 그 사용자의 각 파일당 하나의 항목을 갖고 각 항목은 디스크상에 파일이 저장되어 있는 실제 위치를 가리킴
   - 파일의 이름은 주어진 사용자 디렉터리 내에서만 유일하면 되지만 한 파일의 시스템 이름은 파일 시스템 내에서 유일해야 함
3. 사용자 파일

### 파일 관리자의 기능

파일 관리자는 보조기억장치를 활성화시켜 파일을 할당하고 파일의 기록을 갱신하는 동안 파일을 메모리에 적재하여 테이블을 갱신하거나 수정된 사항이 있다면 파일을 보조기억장치의 같은 장소에 다시 쓰고 그 파일을 해지함

1. 사용자가 파일을 생성, 수정, 삭제 할 수 있게 함
2. 타인의 파일을 공동으로 사용할 수 있게 함
3. 읽기, 쓰기, 실행 및 그 조합까지 여러 종류의 액세스 제어 방법 제공
4. 사용자가 각 응용에 적합한 구조로 파일을 구성할 수 있게 함
5. 백업 및 복구
6. 물리적인 장치 이름 대신 기호화된 이름을 사용하여 파일을 참조할 수 있게 함
7. 정보가 안전하게 보호되고 비밀이 보장되게 함

### 파일 구조

파일을 구성하는 레코드들이 보조기억장치에 배치되는 방식

#### 순차 파일

레코드가 물리적 순서에 따라 저장되어 있는 파일
즉 논리적인 레크도의 순서와 물리적인 레코드의 순서가 동일

- 순차 파일은 순차적으로 기록하고 판독하는 경우에 적절하며 물리적으로 순차적 성질을 가진 장치에 이용
  ex. 테이프 장치

#### 인덱스된 순차 파일

각 레코드의 키를 기준으로 한 논리적 순서대로 레코드가 저장되어 있고 일부 주요 레코드의 실제 주소가 저장된 인덱스를 구성하여 관리하는 파일

- 키 순서에 의해 순차적으로 액세스할 수 있고 인덱스의 검색을 통해 직접 액세스 가능
  ex. 디스크

#### 직접 파일

각 레코드의 키를 이용하여 직접접근 저장장치의 물리적 주소를 통해 직접 액세스되는 파일
즉 논리적인 키와 물리적인 주소의 사상은 프로그래머가 직접 정의해야 함

### 디스크 공간 할당

1. 연속 할당 기법
   보조 기억장치의 연속된 가용공간에 파일 저장공간을 할당하는 방식

- 미리 파일의 저장공간 크기를 정해야 함
- 연속된 레코드들이 보조기억장치에 물리적으로도 서로 인접하게 저장되므로 액세스가 효율적
- 파일 시작주소와 길이로 관리
- 메모리 동적 분할과 같은 외부 단편화 발생
- 주기적으로 집약을 통해 새로운 파일을 넣을 수 있는 공간을 확보해야 함
- 파일 크기 확장에 대한 대응이 비효율적

2. 불연속 할당 기법
   섹터 또는 블록 단위로 공간을 할당하는 방식

- 블록 간 포인터를 이용하여 연결
- 파일 크기가 커지면 현재 파일이 저장되어 있는 블록으로부터 가장 가까운 거리에 있는 블록을 선택하여 그 파일에 추가 할당하고 포인터로 연결
- 외부 단편화와 파일 확장 문제가 발생하지 않음
- 파일 공간이 분산되어 논리적으로 연속된 레코드들을 검색하는 경우 성능저하 발생
- 포인터 관리를 위한 연산 및 공간이 필요하여 추가비용 및 실제 데이터를 저장할 공간이 감소됨

# 분산 시스템

병렬로 문제를 풀 수 있는 컴퓨터를 만드는 방법은 한 대의 컴퓨터에 여러 개의 프로세서를 넣어서 모든 프로세서가 클럭과 메모리를 공유하는 강결합 시스템과 복수의 컴퓨터가 각각 프로세서를 가지고 네트워크를 통해 연결된 약결합 시스템으로 나뉨

## 약결합 시스템

설계의 유리함과 비용절감 문제로 로컬과 원격의 구분이 생기며 각 프로세서의 입장에서 로컬 자원은 자신이 속한 컴퓨터에 속하는 자원이며 원격 자원은 다른 컴퓨터에 속해서 네트워크를 통해야 이용할 수 있는 자원을 말함

## 분산 시스템의 장점

1. 자원 공유: 각 컴퓨터의 자원을 연결된 다른 컴퓨터가 공유하여 사용할 수 있음
2. 성능 향상: 여러 대의 프로세서에 작업을 분할하여 병렬적으로 동시에 수행하는 방식으로 성능을 향상 가능
3. 신뢰성 향상: 하나의 프로세서 또는 자원에 문제가 생긴다 해도 이를 대신할 수 있는 다른 프로세서 자원이 있다면 역할을 대신시켜 작업을 진행해 나갈 수 있음
4. 통신의 편리성

## 분산 시스템 구축 기준

1. 망 구축비용
2. 통신 비용
3. 신뢰성
   => 링크를 많이 연결할수록 망 구축비용이 늘어나지만 통신비용과 신뢰성이 높아짐

## 분산 시스템 종류

### 완전연결 네트워크

모든 사이트는 다른 사이트와 직접 연결되어 있음

- 망 구축비용이 가장 큼
- 노드의 개수가 많은 경우 부적합
- 사이트 간 연결되어 있으므로 통신비용이 최소
- 고장나도 다른 사이트 통신 간 문제가 없음

### 부분연결 네트워크

직접 연결되지 않은 노드 쌍이 존재

- 망 구축비용이 저렴
- 연결되지 않은 노드끼리 다른 노드와 링크를 통해 메시지를 전달
- 고장나서 두 노드가 연결되지 않으면 신뢰성이 떨어질 수 있음

### 트리 구조 네트워크

어떤 두 노드도 연결되도록할 때 링크가 가장 적은 형태

- N개의 노드가 있을 때 링크는 N-1개가 존재(트리 특성)
- 직접 연결된 두 노드 외에는 반드시 다른 노드를 거쳐서 메시지를 주고 받아야 함
- 노드와 링크가 고장날 경우 시스템이 분리될 수 있음

### 스타형 네트워크

하나의 노드가 중심을 이루고 다른 노드들은 모두 중심 노드에 연결된 형태

- N개 노드가 있을 때 링크는 N-1개가 필요
- 어떤 두 노드를 고르더라도 최대 2개의 링크를 거쳐 메시지를 주고 받을 수 있음
- 중심 노드가 고장날 경우 전체 네트워크는 연결이 끊어지게 됨

### 링형 네트워크

전체 노드가 고리를 이루는 형태

- N개의 노드가 있을 때 N개의 링크가 필요
- 두 노드 사이의 링크의 개수는 최소 1, 최대 N/2
- 하나의 노드가 고장나도 연결이 끊어지지 않음

### 버스형 네트워크

버스라고 부르는 빠른 링크에 모든 노드가 연결된 형태

- 노드가 버스에 메시지를 보내면 모든 노드가 이를 읽을 수 있음
- 버스가 고장나면 전체 네트워크가 문제 발생

## 분산 운영체제

분산 시스템을 관리하기 위한 운영체제
사용자가 원격 자원을 로컬 자원을 사용하는 것처럼 쉽게 사용할 수 있고 둘 사이 구별이 없어 투명성을 제공할 수 있어야 함

1. 데이터 이주
   원격 데이터를 로컬을 전송해와서 사용하는 방식

2. 계산 이주
   데이터를 가져오기에 너무 양이 많은 경우 데이터를 가져오는 대신 원격 프로시저 호출(RPC)을 통해 계산을 원격지에서 처리한 후 결과를 전송받는 방식

3. 프로세스 이주
   프로세스 자체를 원격지로 이주시키는 방식
   - 프로세스의 코드, 실행 정보 등을 네트워크 전송

## 분산 파일 시스템

클라이언트가 원격 파일을 로컬 파일처럼 사용할 수 있게 해줌
즉 네트워크를 통해 물리적으로 분리되어 있는 원격 파일 시스템들을 하나의 파일 시스템처럼 이용할 수 있게 해주는 것

### 분산 파일 시스템 구별 방법

1. 파일
   호스트 이름과 그 호스트에서의 로컬 이름을 합쳐서 새로운 이름을 주는 것

2. 마운트
   원격 디렉터리를 로컬 디렉터리에 마운트하는 방식
   ex. NFS(Network File System)

- 마운트: 로컬 파일 시스템을 디렉터리와 연결하는 명령어지만 원격 파일 시스템을 디렉터리와 연결할 수도 있음
  """
  // /dev/ex1 장치에 저장된 ext4 파일 시스템을 /usr/local(로컬) 디렉터리와 연결
  mount -t ext4 /dev/ex1 /usr/local

// IP 주소 10.10.10.10 인 호스트의 /backups 디렉터리를 /var/backups(원격) 디렉터리와 연결
mount -t nfs 10.10.10.10:/backups /var/backups
"""

#### 원격 파일 처리 과정

1. 클라이언트가 파일 서버에 요청
2. RPC을 통해 전달
3. 파일 서버는 클라이언트를 대신하여 디스크에 접근
4. 결과를 네트워크를 통해 전달
   네트워크를 통해 파일을 접근할 수 있게 해주지만 파일에 대한 요청이 커지면 네트워크를 자주 이용해야하므로 효율성에 문제가 생기므로 캐시를 이용하여 네트워크 사용량을 줄이고 전체 시스템의 성능을 높임

#### 파일 서버와 캐시

한번 읽은 데이터는 가까운 장래에 다시 사용될 가능성이 크며 데이터의 어떤 부분을 읽었다면 그 이웃한 부분도 가까운 장래에 다시 사용될 가능성이 크다는 것을 이용
즉 클라이언트가 파일을 요청을하면 서버에서 전송된 데이터를 한 번 사용하고 버리는 것이 아니라 클라이언트의 캐시에 데이터의 복사본이 저장됨

- 캐시 일관성 문제: 캐시에 복사된 데이터와 원래 데이터 사이의 이런 불일치를 해소하고 일관성을 갖게 하는 문제

## 분산 메모리

분산 시스템의 목표 중 하나인 자원을 공유하여 메모리를 효율적으로 이용하는 것

### 원격 메모리

- 로컬 메모리와 보조기억장치를 합친 가상 메모리의 형태로 접근
- 원격 메모리 API를 이용하여 클라이언트/서버 형태로 구성

#### 원격 메모리 구조

1. 프로세스는 전역 주소공간에 매핑된 로컬 주소공간의 이름을 통해 원격 메모리를 참조
   - 원격 메모리에 전송 계층 주소가 할당되면 프로세스는 해당 서버 주소상의 블록과 오프셋을 참조
   - ex. <(net#, host#, port#), block, offset>
2. 컴파일 시간, 적재시간, 런타임 시 로컬 주소공간 등과 원격 메모리의 바인딩을 하도록 원격 메모리 API 설계
   - 런타임 바인딩이 가장 유연하여 많이 사용
   - 원격 메모리의 위치를 알아내고 이를 로컬 주소공간에 바인딩하기 위해 이름 서버를 사용

### 분산 공유 메모리

Distributed Shared Memory (DSM)
물리적으로 분리된 메모리를 하나의 주소공간을 통해 접근할 수 있음

- 가상 메모리 관리자가 메인 메모리와 보조기억장치 사이의 페이지 관리뿐만 아니라 네트워크로 연결된 원격 메모리 서버도 관리
- 가상 메모리 참조에선 가상주소에 실제 로컬 메모리, 보조기억장치, 원격 메모리의 물리주소가 대응됨
- 노드의 개수가 늘어나더라도 잘 확장됨
- 메모리를 공유하기 위해 해야 할 일들을 프로그래머가 신경 쓸 필요 없지만 직접 제어하는 것도 쉽지 않음
- 복잡하고 큰 데이터를 처리하는 데 유리
- 멀티프로세서 시스템에 비해 저렴
- 큰 가상 메모리 공간을 제공
- 분산되지 않은 공유 메모리에 비해 접근속도가 느림
- 성능이 떨어질 수 있음
- 공유 메모리에 저장된 데이터에 대해 둘 이상의 접근이 발생할 때 추가적인 보호 메커니즘 필요

* NUMA(Non-Uniform Memory Access): 각 프로세서가 로컬 메모리를 갖는 분산 공유 메모리 구조

## 원격 프로시저 호출 (Remote Procedure Call, RPC)

프로세스가 다른 주소공간(네트워크로 연결된 다른 컴퓨터)에 있는 프로시저를 실행시키는 것

### 전통적인 프로시저 호출의 동작

1. 매개변수를 스택에 넣음
2. 호출할 프로시저가 있는 위치로 이동

### 원격 프로시저 호출의 동작

1. RPC 사용하려는 클라이언트는 같은 주소공간에 있는 프로시저(스텁 루틴)를 호출
2. 전달 받은 매개변수를 메시지를 포장하여 네트워크를 대기하고 있는 특정 서버에 있는 프로세스에 전달
3. 실행 결과를 메시지로 포장되어 스텁 루틴에 전달
4. 스텁 루틴은 이 메시지를 활용하여 자신의 실행결과처럼 RPC를 호출한 함수에 전달
   => 프로그래머 입장에서는 호출한 함수가 로컬인지 원격인지 여부를 구별할 필요 없어짐

### 원격 프로시저 구현 시 고려사항

1. RPC를 사용하는 것과 로컬 프로시저를 호출하는 것은 구별되지 않아야 함
2. 호출하는 프로시저와 호출되는 프로시저는 서로 다른 주소공간에 속하기 때문에 단순히 메모리 주소를 리턴하는 참조 호출은 의미가 없을 수 있음
   => 참조를 위해선 네트워크에서 해당하는 자원의 이름을 이용해야 함
3. RPC의 수신자는 호출이 생성된 곳과 유사한 환경이어야 함
   => 전역 변수를 통해 정보를 전달하려면 클라이언트와 서버 사이 별도의 통신이 있어야 함

""" theClient
int main() {
...
localF()
remoteF()
...
}

localF() { ... }

// 클라이언트 스텁 루틴
Lookup(remoteF) // 이름 서버
Pack(msg, )
send(rpcServer, msg)
receive(msg)
Unpack(msg, )
"""

""" rpcServer
remoteF() { ... }

// 서버 스텁 루틴
Register(remoteF) // 이름 서버

while(true) {
receive(msg)
Unpack(msg)
remoteF()
Pack(rtnMsg)
send(theClient, rtnMsg)
}
"""

- RPC 은 네트워크 간 통신을 사용하여 다른 컴퓨터에서 동작하는 프로그램들 사이의 분산처리에 유용
- 결과가 올 때까지 프로시저는 동작을 멈추고 대기하므로 고성능을 요구하는 병렬 처리에 적합하지 않음

# 보안

원격 접속하는 사용자에 대한 인증 메커니즘, 암호화 메커니즘 등을 통해 사용자가 누구인지 정확하게 인식하고 이 사용자가 권한을 가진 자원만을 이용하여 허락된 일만 할 수 있도록 보장하여 시스템이 정상적으로 동작함으로 결함이 없고 시스템을 신뢰할 수 있도록 하는 것

# 보호

실행되는 각 프로세스에 대해 자신이 사용하는 자원이 다른 프로세스에 영향을 받지 않도록 하는 것

## 보호 보안의 목적

1. 악의적인 사용자가 시스템 자원에 대한 접근 제한을 의도적으로 위반하는 것을 방지
2. 주변 시스템 간 인터페이스에서 발견하지 못한 잠재적 오류를 적이 이용하기 전에 미리 검출하여 시스템의 신뢰도를 높임
3. 시스템 자원을 권한이 없는 사용자가 잘못 사용하는 것을 막음
4. 권한이 있는 사용자와 없는 사용자를 구별
   즉 시스템 프로세스와 사용자 프로세스에 대해 자신이 권한을 가지지 않은 자원에 대해 접근하는 일을 막는 접근제어를 규정하는 것이 목적임

## 보호영역 (protection domain)

프로세스는 자신의 보호영역 하나를 가지고 있으며 이 안에 포함된 자원은 이 프로세스가 쓸 수 있는 영역

- 접근권한: 각 객체에 대한 프로세스가 연산을 수행할 수 있는 능력
  즉 하나의 보호영역은 이런 접근권한의 집합이며 객체마다 <객체이름, 권한집합> 의 순서쌍으로 주어짐
- 접근권한은 영역 사이에 공유 가능

## 운영체제에서의 보안

운영체제에 포함된 취약점을 이용하여 생길 수 있는 여러 가지 공격으로부터 운영체제가 관리하는 자원을 불법적으로 이용하는 것을 막는 정책과 기법

- 적절한 접근제어 설정
- 정보의 암호화
- 시스템 접속 및 자원 사용에 대한 기록

- 객체: 운영체제 상에서 관리하는 모든 자원을 의미
- 주체: 객체를 사용하고자 하는 프로세스
- 주체는 자신의 임무를 수행하기 위해 객체를 사용하는데 이 사용에는 읽기, 쓰기, 실행 등이 있음

## 운영체제 보안 목표

1. 기밀성

- 운영체제가 관리하는 자원들은 만약 주체가 합법적으로 사용할 수 없다면 사용되어선 안됨
- 불법으로 사용되었다면 탐지할 수 있어야 함

2. 가용성

- 주체가 사용하는데 문제가 없다면 반드시 사용할 수 있어야 함

3. 무결성

- 객체에 저장되어 있는 정보가 항상 정확해야 함
- 객체는 합법적인 경우에만 수정될 수 있어야 함

### 정보침해

운영체제의 세 가지 목표인 기밀성, 가용성, 무결성이 달성되지 못하고 불법적으로 읽히거나 다른 값이 덮어 쓰이는 것

## 운영체제 침해

1. 가로채기

- 기밀성에 대한 공격
- 공격자가 허락박지 않은 컴퓨터 자원에 접근하는 경우

2. 흐름 차단

- 가용성에 대한 공격
- 시스템의 일부를 파괴하거나 사용할 수 없게 만든 경우

3. 변조

- 무결성에 대한 공격
- 공격자가 허락받지 않은 자원에 접근하여 기존에 있던 데이터의 내용을 바꾸는 경우

4. 위조

- 무결성에 대한 공격
- 공격자는 허락받지 않은 자원에 접근하여 기존에 없던 불법적인 정보를 삽입하는 경우

## 운영체제 침해 유형

1. 트로이 목마

- 숨겨진 기능이 있는 프로그램을 사용자가 실행하게 만들어서 이 사용자의 권한을 이용하여 시스템에 침투하는 것

2. 트랩도어

- 정상적인 인증절차나 암호화를 피해갈 수 있는 비밀통로로 데이터를 빼내거나 변조할 수 있음

3. 비밀 채널

- 데이터를 주고받을 수 없는 프로세스 사이에서 정상적인 데이터 전송 메커니즘이 아닌 다른 방법으로 정보를 알아내는 형태의 공격

4. 웜

- 하나의 악성 코드 프로그램으로 자기 자신을 복사하여 다른 컴퓨터에 전파시키는 능력

5. 바이러스

- 스스로를 복사하는 악성 코드면서 다른 프로그램을 감염시켜서 자신의 코드를 다른 프로그램에 추가
- 계속해서 다른 프로그램에 전파시키는 능력으로 자기 자신이 하나의 프로그램은 아님

# 보안정책

보안을 어떠한 관점에서 무엇을 행할 것인가를 결정하는 것

## 권한부여

어떤 주체가 어떤 객체를 어떻게 액세스할 수 있는지 결정

### 식별

어떤 주체나 객체가 무엇인지 신분을 알아내는 것

### 인증

주체와 객체가 정말로 자신이 주장하는 그 주체와 객체가 맞는지 확인하는 것

## 임의적 접근제어

관리자 또는 자원 소유자가 보안 관리자의 개입 없이 주체에 자원의 접근권한을 부여할 수 있음

- 유연하게 자원을 공유할 수 있음
- 누가 권한을 가지고 있는지 판단하기 어려워 관리가 쉽지 않음
- 자원의 보호보다 자원의 공유가 중요할 때 적합

## 강제적 접근제어

운영체제가 각각의 주체가 객체에 대한 접근이나 연산을 할 수 있는지 여부를 정해진 규칙과 비교하여 여부를 결정

- 보안정책이 중앙에서 관리되며 각 사용자는 이 정책을 넘어서 행동할 수 없음
- 주체에는 허가등급, 객체에는 비밀등급이 주어짐 => 접근 요청이 올 때마다 이 둘을 비교하여 허가 여부를 결정
- 보안 관리자가 시스템 전체에 대한 보안정책을 구현하고 강제할 수 있어서 보안에 효율적
- 보안등급을 강제하는 과정에서 자원의 공유가 복잡해질 수 있음
- 자신에게 주어진 권한을 다른 사용자에게 넘기거나 규칙을 수정할 수 없음

## 역할 기반 접근제어 (RBAC)

사용자와 그들의 권한을 효과적으로 역할을 두어 관리하는 방법

### 역할 기반 접근제어의 요소

- 사용자: 사람이나 자동화된 에이전트 => 하나의 사용자는 여러 가지 역할을 가질 수 있음 (사용자:역할=1:N)
- 역할: 권한 수준을 정의하는 일의 기능이나 이름 => 하나의 역할은 여러 가지 권한을 가질 수 있음 (역할:권한=1:N)
- 권한: 특정한 형태로 자원에 대한 접근을 허락하는 것 => 하나의 권한은 여러 역할에 주어질 수 있음
- 세션: 사용자, 역할, 권한 사이의 대응관계
  즉 사용자와 권한 사이는 N:N 관계이다

### 역할 기반 접근제어의 규칙

1. 역할할당: 주체는 역할이 주어졌을 때만 권한을 행사할 수 있음
2. 역할권한부여: 주체가 어떤 역할을 행사하려면 권한을 부여받아야 함
3. 권한부여: 주체는 현재 행사하고 있는 역할에 권한이 주어졌을 때만 권한을 사용할 수 있음

## 최소권한

사용자는 업무를 수행하기 위해 필요한 최소한의 권한을 받아야 하고 임무가 끝나면 이 권한을 반환해야 한다

## 감사 (auditing)

컴퓨터 이벤트는 해당하는 내용에 대한 정보가 기록되어야 하고 특별한 일이 없는 한 이 정보는 변조되지 않고 보존되어야 함
즉 감사 과정을 통해 시스템의 로그 파일을 조사하여 시스템에 발생한 이벤트를 추적하고 침해 사고 등이 발생했는지 여부를 확인하고 감시해야 함

# 보안 메커니즘

보안을 어떠한 방법으로 할 것인가를 결정하는 것

## 주체 및 객체의 레이블 부여 메커니즘

시스템의 주체와 객체마다 유일한 식별자를 부여하여 시스템 안에서 서로 구별이 가능하게 함
각 주체와 객체마다 보안등급을 부여하여 허락되지 않은 접근을 막을 수 있게 함

시스템의 성능과 목적이 허락하는 한 최선의 보안을 구축하는 것이 필요하므로 레이블 부여는 접근제어를 구현하는데 필요함

## 안전한 암호 메커니즘

암호화 기술은 비밀키 암호화 알고리즘과 공개키 암호화 알고리즘으로 나뉜다

## 안전한 인증 메커니즘

식별과 인증을 위한 여러가지 방법이 있음

- 패스워드
- 다요소 인증: 사용자 인증에 두 가지 이상의 방법을 요구하는 것

## 임의적 접근제어를 위한 메커니즘

자원의 소유자가 세 가지 주체를 대상으로 세 가지 연산을 허락할지 금지할지 보안등급을 관리
주체는 자기 자신, 자신이 속한 그룹, 나머지로 나뉘며 가능한 연산은 읽기, 쓰기, 실행하기임

## 보안등급 관리 메커니즘

전체 시스템의 보안을 관리하는 보안 관리자만 사용자에게 다양한 종류의 보안등급을 부여하여 강제적 접근제어가 가능하게 함

## 기록 파일 관리 메커니즘

시스템에서 발생한 이벤트에 대한 기록을 안전한 위치에 보관하고 수정할 수 없게 함

## 운영자 권한의 분산 메커니즘

시스템 관리자의 권한을 세분화하여 목적에 따라 해당하는 역할을 담당하는 운영자에게 줘서 최소권한 부여 원칙을 구현함
